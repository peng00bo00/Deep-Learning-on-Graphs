{"cells":[{"cell_type":"code","source":["!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu113.html"],"metadata":{"id":"DCAZhEC7nnde"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4946toItnht_"},"source":["# 第八课 图深度学习的应用（三）"]},{"cell_type":"markdown","metadata":{"id":"6KDKDgkinhuC"},"source":["在前面两节实践课中，我们了解了图深度学习在知识图谱和计算机视觉中的应用。在今天这节课中，我们将学习图深度学习在推荐系统中的应用。"]},{"cell_type":"markdown","metadata":{"id":"RtOH-BrqnhuC"},"source":["## GNN在推荐系统的应用"]},{"cell_type":"markdown","metadata":{"id":"KrW4W9o5nhuD"},"source":["在本节中我们主要以LightGCN为例，介绍GNN在推荐系统中的应用。\n","\n","注：LightGCN来自论文LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation，见链接https://arxiv.org/abs/2002.02126 。"]},{"cell_type":"markdown","metadata":{"id":"zfVu2mxsnhuD"},"source":["## 1. 推荐系统数据集介绍"]},{"cell_type":"markdown","metadata":{"id":"4YebKKQAnhuE"},"source":["### 1.1 初识Movielens"]},{"cell_type":"markdown","metadata":{"id":"H733btb5nhuE"},"source":["Movielens是推荐系统研究中常用的数据集。从它的名字可以看出，这是一个跟电影有关的数据集，它包含了从IMDB数据库中上用户对电影的评分信息。官网下载地址是https://grouplens.org/datasets/movielens/ 。这里面提供了多个相关数据集，在本次实践课上我们选用小的那个文件(ml-lastest-small.zip)，它仅有1MB。解压后的数据集文件我已经放在了`data/MovieLens/raw/ml-latest-small`文件夹下面：\n"," ```\n","|-- Lecture8.ipynb \n","|-- data\n","    |-- MovieLens\n","        |-- raw\n","            |-- ml-latest-small\n","                |-- README.txt\n","                |-- links.csv\n","                |-- movies.csv\n","                |-- ratings.csv\n","                |-- tags.csv\n"," ```\n"," 我们需要用的文件有两个：`movies.csv`和`ratings.csv`。"]},{"cell_type":"markdown","metadata":{"id":"wI7u4udDnhuF"},"source":["首先我们读取电影信息的表格。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S76PoX_unhuF"},"outputs":[],"source":["import torch\n","import pandas as pd\n","df1 = pd.read_csv('data/MovieLens/raw/ml-latest-small/movies.csv', index_col='movieId')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNVlbllMnhuG","outputId":"157a2e5f-c9b3-45d8-f9b5-cd13cda3c145"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","    <tr>\n","      <th>movieId</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>193581</th>\n","      <td>Black Butler: Book of the Atlantic (2017)</td>\n","      <td>Action|Animation|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>193583</th>\n","      <td>No Game No Life: Zero (2017)</td>\n","      <td>Animation|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>193585</th>\n","      <td>Flint (2017)</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>193587</th>\n","      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n","      <td>Action|Animation</td>\n","    </tr>\n","    <tr>\n","      <th>193609</th>\n","      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9742 rows × 2 columns</p>\n","</div>"],"text/plain":["                                             title  \\\n","movieId                                              \n","1                                 Toy Story (1995)   \n","2                                   Jumanji (1995)   \n","3                          Grumpier Old Men (1995)   \n","4                         Waiting to Exhale (1995)   \n","5               Father of the Bride Part II (1995)   \n","...                                            ...   \n","193581   Black Butler: Book of the Atlantic (2017)   \n","193583                No Game No Life: Zero (2017)   \n","193585                                Flint (2017)   \n","193587         Bungo Stray Dogs: Dead Apple (2018)   \n","193609         Andrew Dice Clay: Dice Rules (1991)   \n","\n","                                              genres  \n","movieId                                               \n","1        Adventure|Animation|Children|Comedy|Fantasy  \n","2                         Adventure|Children|Fantasy  \n","3                                     Comedy|Romance  \n","4                               Comedy|Drama|Romance  \n","5                                             Comedy  \n","...                                              ...  \n","193581               Action|Animation|Comedy|Fantasy  \n","193583                      Animation|Comedy|Fantasy  \n","193585                                         Drama  \n","193587                              Action|Animation  \n","193609                                        Comedy  \n","\n","[9742 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df1"]},{"cell_type":"markdown","metadata":{"id":"H17CfBf9nhuH"},"source":["可以看到，第一列是电影名称，第二列是电影的种类。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFFdMKj0nhuH","outputId":"d9de2eff-3aa1-4c45-a485-b7d1e6e906ea"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>(no genres listed)</th>\n","      <th>Action</th>\n","      <th>Adventure</th>\n","      <th>Animation</th>\n","      <th>Children</th>\n","      <th>Comedy</th>\n","      <th>Crime</th>\n","      <th>Documentary</th>\n","      <th>Drama</th>\n","      <th>Fantasy</th>\n","      <th>Film-Noir</th>\n","      <th>Horror</th>\n","      <th>IMAX</th>\n","      <th>Musical</th>\n","      <th>Mystery</th>\n","      <th>Romance</th>\n","      <th>Sci-Fi</th>\n","      <th>Thriller</th>\n","      <th>War</th>\n","      <th>Western</th>\n","    </tr>\n","    <tr>\n","      <th>movieId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>193581</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>193583</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>193585</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>193587</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>193609</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9742 rows × 20 columns</p>\n","</div>"],"text/plain":["         (no genres listed)  Action  Adventure  Animation  Children  Comedy  \\\n","movieId                                                                       \n","1                         0       0          1          1         1       1   \n","2                         0       0          1          0         1       0   \n","3                         0       0          0          0         0       1   \n","4                         0       0          0          0         0       1   \n","5                         0       0          0          0         0       1   \n","...                     ...     ...        ...        ...       ...     ...   \n","193581                    0       1          0          1         0       1   \n","193583                    0       0          0          1         0       1   \n","193585                    0       0          0          0         0       0   \n","193587                    0       1          0          1         0       0   \n","193609                    0       0          0          0         0       1   \n","\n","         Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  \\\n","movieId                                                                         \n","1            0            0      0        1          0       0     0        0   \n","2            0            0      0        1          0       0     0        0   \n","3            0            0      0        0          0       0     0        0   \n","4            0            0      1        0          0       0     0        0   \n","5            0            0      0        0          0       0     0        0   \n","...        ...          ...    ...      ...        ...     ...   ...      ...   \n","193581       0            0      0        1          0       0     0        0   \n","193583       0            0      0        1          0       0     0        0   \n","193585       0            0      1        0          0       0     0        0   \n","193587       0            0      0        0          0       0     0        0   \n","193609       0            0      0        0          0       0     0        0   \n","\n","         Mystery  Romance  Sci-Fi  Thriller  War  Western  \n","movieId                                                    \n","1              0        0       0         0    0        0  \n","2              0        0       0         0    0        0  \n","3              0        1       0         0    0        0  \n","4              0        1       0         0    0        0  \n","5              0        0       0         0    0        0  \n","...          ...      ...     ...       ...  ...      ...  \n","193581         0        0       0         0    0        0  \n","193583         0        0       0         0    0        0  \n","193585         0        0       0         0    0        0  \n","193587         0        0       0         0    0        0  \n","193609         0        0       0         0    0        0  \n","\n","[9742 rows x 20 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df1['genres'].str.get_dummies('|') # 用get_dummies()实现one-hot编码"]},{"cell_type":"markdown","metadata":{"id":"v6X8dcjNnhuI"},"source":["值得注意的是，get_dummies()可以直接实现one-hot编码。例如，movieId为1的电影的种类是冒险类(Adventure)、动画类(Animation)、儿童类(Children)、喜剧类(Comedy)和科幻类(Fantasy)。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJ3fb_xmnhuI","outputId":"c3af0cbe-2fe5-4020-d212-1e47dcc97c9b"},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n","        [0., 0., 1.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 1., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# 我们可以把上述编码转换成tensor\n","genres = df1['genres'].str.get_dummies('|').values \n","genres = torch.from_numpy(genres).to(torch.float) \n","genres"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vok6zQVUnhuI","outputId":"55113e5e-634c-4706-ae58-792280cd12a3"},"outputs":[{"data":{"text/plain":["{1: 0,\n"," 2: 1,\n"," 3: 2,\n"," 4: 3,\n"," 5: 4,\n"," 6: 5,\n"," 7: 6,\n"," 8: 7,\n"," 9: 8,\n"," 10: 9,\n"," 11: 10,\n"," 12: 11,\n"," 13: 12,\n"," 14: 13,\n"," 15: 14,\n"," 16: 15,\n"," 17: 16,\n"," 18: 17,\n"," 19: 18,\n"," 20: 19,\n"," 21: 20,\n"," 22: 21,\n"," 23: 22,\n"," 24: 23,\n"," 25: 24,\n"," 26: 25,\n"," 27: 26,\n"," 28: 27,\n"," 29: 28,\n"," 30: 29,\n"," 31: 30,\n"," 32: 31,\n"," 34: 32,\n"," 36: 33,\n"," 38: 34,\n"," 39: 35,\n"," 40: 36,\n"," 41: 37,\n"," 42: 38,\n"," 43: 39,\n"," 44: 40,\n"," 45: 41,\n"," 46: 42,\n"," 47: 43,\n"," 48: 44,\n"," 49: 45,\n"," 50: 46,\n"," 52: 47,\n"," 53: 48,\n"," 54: 49,\n"," 55: 50,\n"," 57: 51,\n"," 58: 52,\n"," 60: 53,\n"," 61: 54,\n"," 62: 55,\n"," 63: 56,\n"," 64: 57,\n"," 65: 58,\n"," 66: 59,\n"," 68: 60,\n"," 69: 61,\n"," 70: 62,\n"," 71: 63,\n"," 72: 64,\n"," 73: 65,\n"," 74: 66,\n"," 75: 67,\n"," 76: 68,\n"," 77: 69,\n"," 78: 70,\n"," 79: 71,\n"," 80: 72,\n"," 81: 73,\n"," 82: 74,\n"," 83: 75,\n"," 85: 76,\n"," 86: 77,\n"," 87: 78,\n"," 88: 79,\n"," 89: 80,\n"," 92: 81,\n"," 93: 82,\n"," 94: 83,\n"," 95: 84,\n"," 96: 85,\n"," 97: 86,\n"," 99: 87,\n"," 100: 88,\n"," 101: 89,\n"," 102: 90,\n"," 103: 91,\n"," 104: 92,\n"," 105: 93,\n"," 106: 94,\n"," 107: 95,\n"," 108: 96,\n"," 110: 97,\n"," 111: 98,\n"," 112: 99,\n"," 113: 100,\n"," 116: 101,\n"," 117: 102,\n"," 118: 103,\n"," 119: 104,\n"," 121: 105,\n"," 122: 106,\n"," 123: 107,\n"," 125: 108,\n"," 126: 109,\n"," 128: 110,\n"," 129: 111,\n"," 132: 112,\n"," 135: 113,\n"," 137: 114,\n"," 140: 115,\n"," 141: 116,\n"," 144: 117,\n"," 145: 118,\n"," 146: 119,\n"," 147: 120,\n"," 148: 121,\n"," 149: 122,\n"," 150: 123,\n"," 151: 124,\n"," 152: 125,\n"," 153: 126,\n"," 154: 127,\n"," 155: 128,\n"," 156: 129,\n"," 157: 130,\n"," 158: 131,\n"," 159: 132,\n"," 160: 133,\n"," 161: 134,\n"," 162: 135,\n"," 163: 136,\n"," 164: 137,\n"," 165: 138,\n"," 166: 139,\n"," 168: 140,\n"," 169: 141,\n"," 170: 142,\n"," 171: 143,\n"," 172: 144,\n"," 173: 145,\n"," 174: 146,\n"," 175: 147,\n"," 176: 148,\n"," 177: 149,\n"," 178: 150,\n"," 179: 151,\n"," 180: 152,\n"," 181: 153,\n"," 183: 154,\n"," 184: 155,\n"," 185: 156,\n"," 186: 157,\n"," 187: 158,\n"," 188: 159,\n"," 189: 160,\n"," 190: 161,\n"," 191: 162,\n"," 193: 163,\n"," 194: 164,\n"," 195: 165,\n"," 196: 166,\n"," 198: 167,\n"," 199: 168,\n"," 201: 169,\n"," 202: 170,\n"," 203: 171,\n"," 204: 172,\n"," 205: 173,\n"," 206: 174,\n"," 207: 175,\n"," 208: 176,\n"," 209: 177,\n"," 210: 178,\n"," 211: 179,\n"," 212: 180,\n"," 213: 181,\n"," 214: 182,\n"," 215: 183,\n"," 216: 184,\n"," 217: 185,\n"," 218: 186,\n"," 219: 187,\n"," 220: 188,\n"," 222: 189,\n"," 223: 190,\n"," 224: 191,\n"," 225: 192,\n"," 227: 193,\n"," 228: 194,\n"," 229: 195,\n"," 230: 196,\n"," 231: 197,\n"," 232: 198,\n"," 233: 199,\n"," 234: 200,\n"," 235: 201,\n"," 236: 202,\n"," 237: 203,\n"," 238: 204,\n"," 239: 205,\n"," 240: 206,\n"," 241: 207,\n"," 242: 208,\n"," 243: 209,\n"," 246: 210,\n"," 247: 211,\n"," 248: 212,\n"," 249: 213,\n"," 250: 214,\n"," 251: 215,\n"," 252: 216,\n"," 253: 217,\n"," 254: 218,\n"," 255: 219,\n"," 256: 220,\n"," 257: 221,\n"," 258: 222,\n"," 259: 223,\n"," 260: 224,\n"," 261: 225,\n"," 262: 226,\n"," 263: 227,\n"," 265: 228,\n"," 266: 229,\n"," 267: 230,\n"," 269: 231,\n"," 270: 232,\n"," 271: 233,\n"," 272: 234,\n"," 273: 235,\n"," 274: 236,\n"," 275: 237,\n"," 276: 238,\n"," 277: 239,\n"," 278: 240,\n"," 279: 241,\n"," 280: 242,\n"," 281: 243,\n"," 282: 244,\n"," 283: 245,\n"," 284: 246,\n"," 285: 247,\n"," 287: 248,\n"," 288: 249,\n"," 289: 250,\n"," 290: 251,\n"," 291: 252,\n"," 292: 253,\n"," 293: 254,\n"," 294: 255,\n"," 295: 256,\n"," 296: 257,\n"," 298: 258,\n"," 299: 259,\n"," 300: 260,\n"," 301: 261,\n"," 302: 262,\n"," 303: 263,\n"," 304: 264,\n"," 305: 265,\n"," 306: 266,\n"," 307: 267,\n"," 308: 268,\n"," 310: 269,\n"," 311: 270,\n"," 312: 271,\n"," 313: 272,\n"," 314: 273,\n"," 315: 274,\n"," 316: 275,\n"," 317: 276,\n"," 318: 277,\n"," 319: 278,\n"," 320: 279,\n"," 321: 280,\n"," 322: 281,\n"," 324: 282,\n"," 325: 283,\n"," 326: 284,\n"," 327: 285,\n"," 328: 286,\n"," 329: 287,\n"," 330: 288,\n"," 331: 289,\n"," 332: 290,\n"," 333: 291,\n"," 334: 292,\n"," 335: 293,\n"," 336: 294,\n"," 337: 295,\n"," 338: 296,\n"," 339: 297,\n"," 340: 298,\n"," 341: 299,\n"," 342: 300,\n"," 343: 301,\n"," 344: 302,\n"," 345: 303,\n"," 346: 304,\n"," 347: 305,\n"," 348: 306,\n"," 349: 307,\n"," 350: 308,\n"," 351: 309,\n"," 352: 310,\n"," 353: 311,\n"," 354: 312,\n"," 355: 313,\n"," 356: 314,\n"," 357: 315,\n"," 358: 316,\n"," 359: 317,\n"," 360: 318,\n"," 361: 319,\n"," 362: 320,\n"," 363: 321,\n"," 364: 322,\n"," 365: 323,\n"," 366: 324,\n"," 367: 325,\n"," 368: 326,\n"," 369: 327,\n"," 370: 328,\n"," 371: 329,\n"," 372: 330,\n"," 373: 331,\n"," 374: 332,\n"," 376: 333,\n"," 377: 334,\n"," 378: 335,\n"," 379: 336,\n"," 380: 337,\n"," 381: 338,\n"," 382: 339,\n"," 383: 340,\n"," 384: 341,\n"," 385: 342,\n"," 386: 343,\n"," 387: 344,\n"," 388: 345,\n"," 389: 346,\n"," 390: 347,\n"," 391: 348,\n"," 393: 349,\n"," 405: 350,\n"," 406: 351,\n"," 407: 352,\n"," 408: 353,\n"," 409: 354,\n"," 410: 355,\n"," 412: 356,\n"," 413: 357,\n"," 414: 358,\n"," 415: 359,\n"," 416: 360,\n"," 417: 361,\n"," 418: 362,\n"," 419: 363,\n"," 420: 364,\n"," 421: 365,\n"," 422: 366,\n"," 423: 367,\n"," 424: 368,\n"," 425: 369,\n"," 426: 370,\n"," 427: 371,\n"," 428: 372,\n"," 429: 373,\n"," 430: 374,\n"," 431: 375,\n"," 432: 376,\n"," 433: 377,\n"," 434: 378,\n"," 435: 379,\n"," 436: 380,\n"," 437: 381,\n"," 438: 382,\n"," 440: 383,\n"," 441: 384,\n"," 442: 385,\n"," 444: 386,\n"," 445: 387,\n"," 446: 388,\n"," 448: 389,\n"," 449: 390,\n"," 450: 391,\n"," 451: 392,\n"," 452: 393,\n"," 453: 394,\n"," 454: 395,\n"," 455: 396,\n"," 456: 397,\n"," 457: 398,\n"," 458: 399,\n"," 459: 400,\n"," 460: 401,\n"," 461: 402,\n"," 464: 403,\n"," 466: 404,\n"," 467: 405,\n"," 468: 406,\n"," 469: 407,\n"," 470: 408,\n"," 471: 409,\n"," 472: 410,\n"," 473: 411,\n"," 474: 412,\n"," 475: 413,\n"," 476: 414,\n"," 477: 415,\n"," 478: 416,\n"," 479: 417,\n"," 480: 418,\n"," 481: 419,\n"," 482: 420,\n"," 484: 421,\n"," 485: 422,\n"," 486: 423,\n"," 487: 424,\n"," 488: 425,\n"," 489: 426,\n"," 490: 427,\n"," 491: 428,\n"," 492: 429,\n"," 493: 430,\n"," 494: 431,\n"," 495: 432,\n"," 496: 433,\n"," 497: 434,\n"," 499: 435,\n"," 500: 436,\n"," 501: 437,\n"," 502: 438,\n"," 504: 439,\n"," 505: 440,\n"," 506: 441,\n"," 507: 442,\n"," 508: 443,\n"," 509: 444,\n"," 510: 445,\n"," 511: 446,\n"," 512: 447,\n"," 513: 448,\n"," 514: 449,\n"," 515: 450,\n"," 516: 451,\n"," 517: 452,\n"," 518: 453,\n"," 519: 454,\n"," 520: 455,\n"," 521: 456,\n"," 522: 457,\n"," 523: 458,\n"," 524: 459,\n"," 526: 460,\n"," 527: 461,\n"," 528: 462,\n"," 529: 463,\n"," 531: 464,\n"," 532: 465,\n"," 533: 466,\n"," 534: 467,\n"," 535: 468,\n"," 536: 469,\n"," 537: 470,\n"," 538: 471,\n"," 539: 472,\n"," 540: 473,\n"," 541: 474,\n"," 542: 475,\n"," 543: 476,\n"," 544: 477,\n"," 546: 478,\n"," 547: 479,\n"," 548: 480,\n"," 549: 481,\n"," 550: 482,\n"," 551: 483,\n"," 552: 484,\n"," 553: 485,\n"," 555: 486,\n"," 556: 487,\n"," 558: 488,\n"," 562: 489,\n"," 563: 490,\n"," 564: 491,\n"," 567: 492,\n"," 568: 493,\n"," 569: 494,\n"," 573: 495,\n"," 574: 496,\n"," 575: 497,\n"," 577: 498,\n"," 579: 499,\n"," 580: 500,\n"," 581: 501,\n"," 583: 502,\n"," 585: 503,\n"," 586: 504,\n"," 587: 505,\n"," 588: 506,\n"," 589: 507,\n"," 590: 508,\n"," 592: 509,\n"," 593: 510,\n"," 594: 511,\n"," 595: 512,\n"," 596: 513,\n"," 597: 514,\n"," 599: 515,\n"," 600: 516,\n"," 602: 517,\n"," 605: 518,\n"," 606: 519,\n"," 608: 520,\n"," 609: 521,\n"," 610: 522,\n"," 611: 523,\n"," 612: 524,\n"," 613: 525,\n"," 615: 526,\n"," 616: 527,\n"," 617: 528,\n"," 618: 529,\n"," 619: 530,\n"," 626: 531,\n"," 627: 532,\n"," 628: 533,\n"," 631: 534,\n"," 632: 535,\n"," 633: 536,\n"," 634: 537,\n"," 635: 538,\n"," 636: 539,\n"," 637: 540,\n"," 638: 541,\n"," 639: 542,\n"," 640: 543,\n"," 645: 544,\n"," 647: 545,\n"," 648: 546,\n"," 649: 547,\n"," 650: 548,\n"," 653: 549,\n"," 656: 550,\n"," 661: 551,\n"," 662: 552,\n"," 663: 553,\n"," 665: 554,\n"," 667: 555,\n"," 668: 556,\n"," 670: 557,\n"," 671: 558,\n"," 673: 559,\n"," 674: 560,\n"," 678: 561,\n"," 679: 562,\n"," 680: 563,\n"," 685: 564,\n"," 688: 565,\n"," 691: 566,\n"," 692: 567,\n"," 694: 568,\n"," 695: 569,\n"," 697: 570,\n"," 698: 571,\n"," 700: 572,\n"," 703: 573,\n"," 704: 574,\n"," 706: 575,\n"," 707: 576,\n"," 708: 577,\n"," 709: 578,\n"," 710: 579,\n"," 711: 580,\n"," 714: 581,\n"," 715: 582,\n"," 718: 583,\n"," 719: 584,\n"," 720: 585,\n"," 722: 586,\n"," 724: 587,\n"," 725: 588,\n"," 726: 589,\n"," 728: 590,\n"," 731: 591,\n"," 733: 592,\n"," 735: 593,\n"," 736: 594,\n"," 737: 595,\n"," 741: 596,\n"," 742: 597,\n"," 743: 598,\n"," 745: 599,\n"," 747: 600,\n"," 748: 601,\n"," 750: 602,\n"," 757: 603,\n"," 759: 604,\n"," 760: 605,\n"," 761: 606,\n"," 762: 607,\n"," 764: 608,\n"," 765: 609,\n"," 766: 610,\n"," 773: 611,\n"," 775: 612,\n"," 778: 613,\n"," 779: 614,\n"," 780: 615,\n"," 781: 616,\n"," 782: 617,\n"," 783: 618,\n"," 784: 619,\n"," 785: 620,\n"," 786: 621,\n"," 788: 622,\n"," 790: 623,\n"," 791: 624,\n"," 795: 625,\n"," 798: 626,\n"," 799: 627,\n"," 800: 628,\n"," 801: 629,\n"," 802: 630,\n"," 803: 631,\n"," 804: 632,\n"," 805: 633,\n"," 806: 634,\n"," 808: 635,\n"," 809: 636,\n"," 810: 637,\n"," 813: 638,\n"," 818: 639,\n"," 823: 640,\n"," 824: 641,\n"," 828: 642,\n"," 829: 643,\n"," 830: 644,\n"," 832: 645,\n"," 833: 646,\n"," 835: 647,\n"," 836: 648,\n"," 837: 649,\n"," 838: 650,\n"," 839: 651,\n"," 840: 652,\n"," 841: 653,\n"," 842: 654,\n"," 848: 655,\n"," 849: 656,\n"," 851: 657,\n"," 852: 658,\n"," 858: 659,\n"," 861: 660,\n"," 866: 661,\n"," 867: 662,\n"," 869: 663,\n"," 870: 664,\n"," 875: 665,\n"," 876: 666,\n"," 879: 667,\n"," 880: 668,\n"," 881: 669,\n"," 882: 670,\n"," 885: 671,\n"," 886: 672,\n"," 888: 673,\n"," 889: 674,\n"," 891: 675,\n"," 892: 676,\n"," 893: 677,\n"," 896: 678,\n"," 897: 679,\n"," 898: 680,\n"," 899: 681,\n"," 900: 682,\n"," 901: 683,\n"," 902: 684,\n"," 903: 685,\n"," 904: 686,\n"," 905: 687,\n"," 906: 688,\n"," 907: 689,\n"," 908: 690,\n"," 909: 691,\n"," 910: 692,\n"," 911: 693,\n"," 912: 694,\n"," 913: 695,\n"," 914: 696,\n"," 915: 697,\n"," 916: 698,\n"," 917: 699,\n"," 918: 700,\n"," 919: 701,\n"," 920: 702,\n"," 921: 703,\n"," 922: 704,\n"," 923: 705,\n"," 924: 706,\n"," 926: 707,\n"," 927: 708,\n"," 928: 709,\n"," 929: 710,\n"," 930: 711,\n"," 931: 712,\n"," 932: 713,\n"," 933: 714,\n"," 934: 715,\n"," 935: 716,\n"," 936: 717,\n"," 937: 718,\n"," 938: 719,\n"," 940: 720,\n"," 941: 721,\n"," 942: 722,\n"," 943: 723,\n"," 944: 724,\n"," 945: 725,\n"," 946: 726,\n"," 947: 727,\n"," 948: 728,\n"," 949: 729,\n"," 950: 730,\n"," 951: 731,\n"," 952: 732,\n"," 953: 733,\n"," 954: 734,\n"," 955: 735,\n"," 956: 736,\n"," 959: 737,\n"," 961: 738,\n"," 963: 739,\n"," 965: 740,\n"," 968: 741,\n"," 969: 742,\n"," 970: 743,\n"," 971: 744,\n"," 973: 745,\n"," 976: 746,\n"," 979: 747,\n"," 981: 748,\n"," 982: 749,\n"," 984: 750,\n"," 986: 751,\n"," 987: 752,\n"," 988: 753,\n"," 990: 754,\n"," 991: 755,\n"," 993: 756,\n"," 994: 757,\n"," 996: 758,\n"," 998: 759,\n"," 999: 760,\n"," 1003: 761,\n"," 1004: 762,\n"," 1005: 763,\n"," 1006: 764,\n"," 1007: 765,\n"," 1008: 766,\n"," 1009: 767,\n"," 1010: 768,\n"," 1011: 769,\n"," 1012: 770,\n"," 1013: 771,\n"," 1014: 772,\n"," 1015: 773,\n"," 1016: 774,\n"," 1017: 775,\n"," 1018: 776,\n"," 1019: 777,\n"," 1020: 778,\n"," 1021: 779,\n"," 1022: 780,\n"," 1023: 781,\n"," 1024: 782,\n"," 1025: 783,\n"," 1027: 784,\n"," 1028: 785,\n"," 1029: 786,\n"," 1030: 787,\n"," 1031: 788,\n"," 1032: 789,\n"," 1033: 790,\n"," 1034: 791,\n"," 1035: 792,\n"," 1036: 793,\n"," 1037: 794,\n"," 1040: 795,\n"," 1041: 796,\n"," 1042: 797,\n"," 1043: 798,\n"," 1046: 799,\n"," 1047: 800,\n"," 1049: 801,\n"," 1050: 802,\n"," 1051: 803,\n"," 1053: 804,\n"," 1054: 805,\n"," 1055: 806,\n"," 1056: 807,\n"," 1057: 808,\n"," 1059: 809,\n"," 1060: 810,\n"," 1061: 811,\n"," 1064: 812,\n"," 1066: 813,\n"," 1068: 814,\n"," 1073: 815,\n"," 1076: 816,\n"," 1077: 817,\n"," 1078: 818,\n"," 1079: 819,\n"," 1080: 820,\n"," 1081: 821,\n"," 1082: 822,\n"," 1083: 823,\n"," 1084: 824,\n"," 1085: 825,\n"," 1086: 826,\n"," 1088: 827,\n"," 1089: 828,\n"," 1090: 829,\n"," 1091: 830,\n"," 1092: 831,\n"," 1093: 832,\n"," 1094: 833,\n"," 1095: 834,\n"," 1096: 835,\n"," 1097: 836,\n"," 1099: 837,\n"," 1100: 838,\n"," 1101: 839,\n"," 1103: 840,\n"," 1104: 841,\n"," 1105: 842,\n"," 1107: 843,\n"," 1111: 844,\n"," 1112: 845,\n"," 1114: 846,\n"," 1116: 847,\n"," 1117: 848,\n"," 1119: 849,\n"," 1120: 850,\n"," 1121: 851,\n"," 1123: 852,\n"," 1124: 853,\n"," 1125: 854,\n"," 1126: 855,\n"," 1127: 856,\n"," 1128: 857,\n"," 1129: 858,\n"," 1130: 859,\n"," 1131: 860,\n"," 1132: 861,\n"," 1135: 862,\n"," 1136: 863,\n"," 1137: 864,\n"," 1140: 865,\n"," 1144: 866,\n"," 1147: 867,\n"," 1148: 868,\n"," 1150: 869,\n"," 1151: 870,\n"," 1156: 871,\n"," 1161: 872,\n"," 1162: 873,\n"," 1163: 874,\n"," 1167: 875,\n"," 1170: 876,\n"," 1171: 877,\n"," 1172: 878,\n"," 1173: 879,\n"," 1175: 880,\n"," 1176: 881,\n"," 1177: 882,\n"," 1178: 883,\n"," 1179: 884,\n"," 1180: 885,\n"," 1183: 886,\n"," 1184: 887,\n"," 1185: 888,\n"," 1186: 889,\n"," 1187: 890,\n"," 1188: 891,\n"," 1189: 892,\n"," 1190: 893,\n"," 1191: 894,\n"," 1192: 895,\n"," 1193: 896,\n"," 1194: 897,\n"," 1196: 898,\n"," 1197: 899,\n"," 1198: 900,\n"," 1199: 901,\n"," 1200: 902,\n"," 1201: 903,\n"," 1202: 904,\n"," 1203: 905,\n"," 1204: 906,\n"," 1206: 907,\n"," 1207: 908,\n"," 1208: 909,\n"," 1209: 910,\n"," 1210: 911,\n"," 1211: 912,\n"," 1212: 913,\n"," 1213: 914,\n"," 1214: 915,\n"," 1215: 916,\n"," 1216: 917,\n"," 1217: 918,\n"," 1218: 919,\n"," 1219: 920,\n"," 1220: 921,\n"," 1221: 922,\n"," 1222: 923,\n"," 1223: 924,\n"," 1224: 925,\n"," 1225: 926,\n"," 1226: 927,\n"," 1227: 928,\n"," 1228: 929,\n"," 1230: 930,\n"," 1231: 931,\n"," 1232: 932,\n"," 1233: 933,\n"," 1234: 934,\n"," 1235: 935,\n"," 1236: 936,\n"," 1237: 937,\n"," 1238: 938,\n"," 1240: 939,\n"," 1241: 940,\n"," 1242: 941,\n"," 1243: 942,\n"," 1244: 943,\n"," 1245: 944,\n"," 1246: 945,\n"," 1247: 946,\n"," 1248: 947,\n"," 1249: 948,\n"," 1250: 949,\n"," 1251: 950,\n"," 1252: 951,\n"," 1253: 952,\n"," 1254: 953,\n"," 1255: 954,\n"," 1256: 955,\n"," 1257: 956,\n"," 1258: 957,\n"," 1259: 958,\n"," 1260: 959,\n"," 1261: 960,\n"," 1262: 961,\n"," 1263: 962,\n"," 1264: 963,\n"," 1265: 964,\n"," 1266: 965,\n"," 1267: 966,\n"," 1268: 967,\n"," 1269: 968,\n"," 1270: 969,\n"," 1271: 970,\n"," 1272: 971,\n"," 1273: 972,\n"," 1274: 973,\n"," 1275: 974,\n"," 1276: 975,\n"," 1277: 976,\n"," 1278: 977,\n"," 1279: 978,\n"," 1280: 979,\n"," 1281: 980,\n"," 1282: 981,\n"," 1283: 982,\n"," 1284: 983,\n"," 1285: 984,\n"," 1286: 985,\n"," 1287: 986,\n"," 1288: 987,\n"," 1289: 988,\n"," 1290: 989,\n"," 1291: 990,\n"," 1292: 991,\n"," 1293: 992,\n"," 1295: 993,\n"," 1296: 994,\n"," 1297: 995,\n"," 1298: 996,\n"," 1299: 997,\n"," 1300: 998,\n"," 1301: 999,\n"," ...}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# movieID不是连续的，这里我们重新映射一下，使序号变得连续 (后面会用到)并且从零开始\n","movie_mapping = {idx: i for i, idx in enumerate(df1.index)}\n","movie_mapping"]},{"cell_type":"markdown","metadata":{"id":"jGMjdXENnhuJ"},"source":["下面我们读取用户评分表。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVxzHOgtnhuJ"},"outputs":[],"source":["df2 = pd.read_csv('data/MovieLens/raw/ml-latest-small/ratings.csv') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jc7NS6lOnhuJ","outputId":"d712a417-381d-4167-a568-fb05de00bc4c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>964982703</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>964981247</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>4.0</td>\n","      <td>964982224</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>5.0</td>\n","      <td>964983815</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>5.0</td>\n","      <td>964982931</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>100831</th>\n","      <td>610</td>\n","      <td>166534</td>\n","      <td>4.0</td>\n","      <td>1493848402</td>\n","    </tr>\n","    <tr>\n","      <th>100832</th>\n","      <td>610</td>\n","      <td>168248</td>\n","      <td>5.0</td>\n","      <td>1493850091</td>\n","    </tr>\n","    <tr>\n","      <th>100833</th>\n","      <td>610</td>\n","      <td>168250</td>\n","      <td>5.0</td>\n","      <td>1494273047</td>\n","    </tr>\n","    <tr>\n","      <th>100834</th>\n","      <td>610</td>\n","      <td>168252</td>\n","      <td>5.0</td>\n","      <td>1493846352</td>\n","    </tr>\n","    <tr>\n","      <th>100835</th>\n","      <td>610</td>\n","      <td>170875</td>\n","      <td>3.0</td>\n","      <td>1493846415</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100836 rows × 4 columns</p>\n","</div>"],"text/plain":["        userId  movieId  rating   timestamp\n","0            1        1     4.0   964982703\n","1            1        3     4.0   964981247\n","2            1        6     4.0   964982224\n","3            1       47     5.0   964983815\n","4            1       50     5.0   964982931\n","...        ...      ...     ...         ...\n","100831     610   166534     4.0  1493848402\n","100832     610   168248     5.0  1493850091\n","100833     610   168250     5.0  1494273047\n","100834     610   168252     5.0  1493846352\n","100835     610   170875     3.0  1493846415\n","\n","[100836 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df2"]},{"cell_type":"markdown","metadata":{"id":"GYdfR4xcnhuJ"},"source":["上面的用户-电影表对应了一个交互矩阵，矩阵中的元素表示用户对电影的评分。值得注意的是，我们可以将该矩阵转换成一个二分图，如下图所示。"]},{"cell_type":"markdown","metadata":{"id":"Q0f_xquknhuK"},"source":["![](graph.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQimIa3xnhuK"},"outputs":[],"source":["# 在转换成图之前，我们把用户的ID也映射（重新排序）一下，使其连续且从零开始\n","user_mapping = {idx: i for i, idx in enumerate(df2['userId'].unique())}\n","# data['user'].num_nodes = len(user_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4_r6Z-OinhuK","outputId":"d474aa36-c9b6-4dcd-ae49-8ca699c8d895"},"outputs":[{"name":"stdout","output_type":"stream","text":["用户数量: 610 物品数量: 9742\n"]}],"source":["num_users = len(user_mapping)\n","num_movies = len(movie_mapping)\n","print('用户数量:', num_users, '物品数量:', num_movies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sCki5OPnhuK"},"outputs":[],"source":["user_src = [user_mapping[idx] for idx in df2['userId']] # 起始节点\n","movie_dst = [movie_mapping[idx]+num_users for idx in df2['movieId']] # 终止节点\n","edge_index = torch.tensor([user_src, movie_dst])\n","rating = torch.from_numpy(df2['rating'].values).to(torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dnagm0Q_nhuL","outputId":"9e363cdf-1a30-4d10-b172-2188793874a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["边索引: tensor([[    0,     0,     0,  ...,   609,   609,   609],\n","        [  610,   612,   615,  ..., 10072, 10073, 10113]])\n","边的权重: tensor([4, 4, 4,  ..., 5, 5, 3])\n"]}],"source":["print('边索引:', edge_index)\n","print('边的标签:', rating)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dv-PsTp-nhuL","outputId":"288613e1-b865-4dea-d738-9da3a5f1d0fa"},"outputs":[{"data":{"text/plain":["(torch.Size([2, 100836]), torch.Size([100836]))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["edge_index.shape, rating.shape"]},{"cell_type":"markdown","metadata":{"id":"CN9YL2fvnhuL"},"source":["### 1.2 构造图数据集"]},{"cell_type":"markdown","metadata":{"id":"Jikaf7HgnhuL"},"source":["接下来我们演示如何构建一个可以被图神经网络使用的Movielens图数据。"]},{"cell_type":"markdown","metadata":{"id":"z9EbMcx9nhuL"},"source":["首先，我们的标签信息是什么呢？很显然，标签信息就是用户评分`rating`。我们把`rating`作为`edge_index`的标签。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUgxMOXYnhuL"},"outputs":[],"source":["edge_label_index = torch.arange(len(rating)) # 带标签的边索引的序号"]},{"cell_type":"markdown","metadata":{"id":"li0PVraMnhuM"},"source":["有了`edge_index`之后，我们就可以直接用它们来表示这个用户-电影二分图了，我们也可以构造一个稀疏矩阵（这个我们留为作业）。但是，前面得到的`edge_index`是有向的，我们需要把它变成无向边（对称的）。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Meyz4CFQnhuM","outputId":"03e9a734-fef6-4792-9423-f4e29fe074e0"},"outputs":[{"data":{"text/plain":["tensor([[    0,     0,     0,  ...,   609,   609,   609],\n","        [  610,   612,   615,  ..., 10072, 10073, 10113]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["edge_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLBd6a5qnhuM","outputId":"2d7ae129-1d8a-4eb6-fbb5-2e5348610170"},"outputs":[{"data":{"text/plain":["10352"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["num_nodes = edge_index.max().item() + 1\n","num_nodes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6W7MjLlnhuM"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","edge_index = edge_index.to(device)\n","rating = rating.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2r47ZHbnhuM"},"outputs":[],"source":["def to_undirected(edge_index):\n","    edge_index_rev = torch.stack([edge_index[1], edge_index[0]]) # 反向边\n","    edge_index_sym = torch.cat([edge_index, edge_index_rev], dim=1)\n","    return edge_index_sym"]},{"cell_type":"markdown","metadata":{"id":"8DtE3MIwnhuN"},"source":["然后，我们需要构造训练集、验证集和测试集。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6E4yWEmnhuN"},"outputs":[],"source":["_N = len(rating)\n","indicies_perm = torch.randperm(_N)\n","idx_train = indicies_perm[: int(0.8*_N)]\n","train_edge_index = edge_index[:, idx_train]\n","train_edge_label = rating[idx_train]\n","\n","idx_val = indicies_perm[int(0.8*_N): int(0.9*_N)]\n","val_edge_index = edge_index[:, idx_val]\n","val_edge_label = rating[idx_val]\n","\n","idx_test = indicies_perm[int(0.9*_N): ]\n","test_edge_index = edge_index[:, idx_test]\n","test_edge_label = rating[idx_test]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwYXQ3K7nhuN","outputId":"14d6c8a3-8530-40f1-95be-7068c2542d97"},"outputs":[{"data":{"text/plain":["(torch.Size([2, 161336]), torch.Size([2, 181504]))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_graph_edge_index = to_undirected(train_edge_index)\n","test_graph_edge_index = to_undirected(torch.cat([train_edge_index, val_edge_index], dim=1))\n","train_graph_edge_index.shape, test_graph_edge_index.shape"]},{"cell_type":"markdown","metadata":{"id":"hjw9ztm8nhuN"},"source":["到这里，我们就构建完毕图数据集了。有的同学可能会问了，“那节点的特征是什么呢？”对于这里的图数据集，我们可以利用一个可学习的embedding层作为节点特征，我们第二节要讲的模型(LightGCN)就是这么做的。那么还有的同学会问了，“我们可不可以用电影的标题和种类的文本特征呢？” 答案是，当然可以。我们会在第三节提到这种方式。"]},{"cell_type":"markdown","metadata":{"id":"ZcmvfR-5nhuN"},"source":["## 2. 使用LightGCN进行推荐"]},{"cell_type":"markdown","metadata":{"id":"n7JjwMgjnhuN"},"source":["我们用$\\mathbf{E}^{(k)}$表示节点在第K层LightGCN的embedding，${\\bf A}$表示图的邻接矩阵。LightGCN的聚合信息（Propagation）过程可以表示如下："]},{"cell_type":"markdown","metadata":{"id":"zbffIKbjnhuO"},"source":["$$\n","\\mathbf{E}^{(k+1)}=\\left(\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A D}^{-\\frac{1}{2}}\\right) \\mathbf{E}^{(k)}\n","$$\n","\n","其中$\\alpha_{0}=\\alpha_{1}=\\ldots=\\alpha_{K}=\\frac{1}{K + 1}$是一个常量。不难看出，LightGCN聚合信息的过程是不包含参数的，这点和GCN不一样（GCN里包含了变换矩阵${\\bf W}$）。最后的节点的embedding是对每一层的embedding进行加权求和。\n","\n","$$\n","\\begin{aligned}\n","\\mathbf{E} &=\\alpha_{0} \\mathbf{E}^{(0)}+\\alpha_{1} \\mathbf{E}^{(1)}+\\alpha_{2} \\mathbf{E}^{(2)}+\\ldots+\\alpha_{K} \\mathbf{E}^{(K)} \\\\\n","&=\\alpha_{0} \\mathbf{E}^{(0)}+\\alpha_{1} \\tilde{\\mathbf{A}} \\mathbf{E}^{(0)}+\\alpha_{2} \\tilde{\\mathbf{A}}^{2} \\mathbf{E}^{(0)}+\\ldots+\\alpha_{K} \\tilde{\\mathbf{A}}^{K} \\mathbf{E}^{(0)}\n","\\end{aligned}\n","$$\n","其中$\\tilde{\\mathbf{A}} =\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A D}^{-\\frac{1}{2}} $。"]},{"cell_type":"markdown","metadata":{"id":"cKpwsPYinhuO"},"source":["那我们来用PyG实现一下LightGCN的聚合过程。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QrPA98RUnhuO"},"outputs":[],"source":["from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.nn.conv.gcn_conv import gcn_norm\n","\n","class LGConv(MessagePassing):\n","    def __init__(self, normalize=True, **kwargs):\n","        kwargs.setdefault('aggr', 'add') # 设置聚合信息的方式为求和(add)\n","        super().__init__()\n","        self.normalize = normalize\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        \"\"\"前向传播，聚合邻居的信息\"\"\"\n","        if self.normalize:\n","            out = gcn_norm(edge_index, edge_weight, x.size(self.node_dim),\n","                           add_self_loops=False, dtype=x.dtype) # LightGCN中不需要对图加一个自环。\n","            edge_index, edge_weight = out\n","\n","        return self.propagate(edge_index, x=x, edge_weight=edge_weight, size=None)\n","\n","    def message(self, x_j, edge_weight):\n","        \"\"\"聚合信息的时候，怎么加权\"\"\"\n","        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTWKVgawnhuO"},"outputs":[],"source":["from torch.nn import ModuleList, Embedding, Linear, ReLU\n","import torch.nn.functional as F\n","\n","class LightGCN(torch.nn.Module):\n","    def __init__(self, num_nodes, embedding_dim, num_layers):\n","        super().__init__()\n","\n","        self.num_nodes = num_nodes\n","        self.embedding_dim = embedding_dim\n","        self.num_layers = num_layers\n","\n","        alpha = 1. / (num_layers + 1)\n","        self.alpha = torch.tensor([alpha] * (num_layers + 1))\n","\n","        self.embedding = Embedding(num_nodes, embedding_dim)\n","        self.convs = ModuleList([LGConv() for _ in range(num_layers)])\n","        self.decoder = torch.nn.Sequential(Linear(2 * embedding_dim, embedding_dim), \n","                                           ReLU(), Linear(embedding_dim, 1))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.embedding.reset_parameters()\n","\n","    def get_embedding(self, edge_index):\n","        x = self.embedding.weight # 输入特征\n","        out = x * self.alpha[0]\n","\n","        for i in range(self.num_layers):\n","            x = self.convs[i](x, edge_index) \n","            out = out + x * self.alpha[i + 1]\n","        return out\n","\n","    def forward(self, edge_index, edge_label_index):\n","        \"\"\"预测节点对的rating\"\"\"\n","        out = self.get_embedding(edge_index) # 每个节点的embedding\n","        out_src = out[edge_label_index[0]] # 起始节点的embedding\n","        out_dst = out[edge_label_index[1]] # 终止节点的embedding\n","        pred = self.decoder(torch.cat([out_src, out_dst], dim=-1))\n","        return pred"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Q3nDYpBknhuO","outputId":"f1e71169-b726-47af-f17a-63020dd547c7"},"outputs":[{"data":{"text/plain":["tensor([25.9817,  7.7208,  2.6808,  1.0710,  1.0000,  2.6757], device='cuda:0')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["#  由于这个数据集的标签非常不均衡：大量的评分是3和4，而仅有少量的评分是0和1。因此我们使用加权的MSE损失函数\n","weight = torch.bincount(train_edge_label)\n","weight = weight.max() / weight\n","weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9bq9W4-nhuP"},"outputs":[],"source":["def weighted_mse_loss(pred, target, weight=None):\n","    weight = 1. if weight is None else weight[target].to(pred.dtype)\n","    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7i58hyTnhuP","outputId":"4c306c2a-73ba-409b-cd5c-e89dfe36ebb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 020, Loss: 6.7103, Train: 1.7786, Val: 1.8073, Test: 1.7968\n","Epoch: 040, Loss: 5.4593, Train: 1.4295, Val: 1.4765, Test: 1.4625\n","Epoch: 060, Loss: 4.8252, Train: 1.2800, Val: 1.3275, Test: 1.3081\n","Epoch: 080, Loss: 4.1315, Train: 1.2389, Val: 1.2931, Test: 1.2642\n","Epoch: 100, Loss: 3.4720, Train: 1.1670, Val: 1.2295, Test: 1.1946\n","Epoch: 120, Loss: 2.9886, Train: 1.1112, Val: 1.1872, Test: 1.1497\n","Epoch: 140, Loss: 2.6723, Train: 1.0705, Val: 1.1615, Test: 1.1266\n","Epoch: 160, Loss: 2.4885, Train: 1.0466, Val: 1.1510, Test: 1.1183\n","Epoch: 180, Loss: 2.3864, Train: 1.0324, Val: 1.1466, Test: 1.1158\n","Epoch: 200, Loss: 2.3285, Train: 1.0234, Val: 1.1449, Test: 1.1149\n","Epoch: 220, Loss: 2.2945, Train: 1.0175, Val: 1.1444, Test: 1.1148\n","Epoch: 240, Loss: 2.2732, Train: 1.0138, Val: 1.1446, Test: 1.1150\n","Epoch: 260, Loss: 2.2588, Train: 1.0111, Val: 1.1448, Test: 1.1152\n","Epoch: 280, Loss: 2.2469, Train: 1.0091, Val: 1.1455, Test: 1.1160\n","Epoch: 300, Loss: 2.2362, Train: 1.0062, Val: 1.1445, Test: 1.1153\n"]}],"source":["model = LightGCN(num_nodes=num_nodes, embedding_dim=32, num_layers=10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    pred = model(train_graph_edge_index, train_edge_index)\n","    target = train_edge_label.view(-1,1)\n","    loss = weighted_mse_loss(pred, target, weight)\n","    loss.backward()\n","    optimizer.step()\n","    return float(loss)\n","\n","\n","@torch.no_grad()\n","def test(graph, dev_edge_index, dev_edge_label):\n","    model.eval()\n","    pred = model(graph, dev_edge_index)\n","    pred = pred.clamp(min=0, max=5) # 限制预测值在0-5\n","    target = dev_edge_label.view(-1,1)\n","    rmse = F.mse_loss(pred, target).sqrt()\n","    return float(rmse)\n","\n","\n","for epoch in range(1, 301):\n","    loss = train()\n","    train_rmse = test(train_graph_edge_index, train_edge_index, train_edge_label)\n","    val_rmse = test(train_graph_edge_index, val_edge_index, val_edge_label)\n","    test_rmse = test(test_graph_edge_index, test_edge_index, test_edge_label)\n","    if epoch % 20 == 0:\n","        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n","              f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"OfswJDpcnhuP"},"source":["训练完模型后，我们来测试一下推荐的效果："]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSNBs3XWnhuP","outputId":"d490099e-9a67-4867-bc13-33ac81ba2e22"},"outputs":[{"data":{"text/plain":["tensor([  610,   612,   615,  ..., 10072, 10073, 10113])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["user_id = 0\n","movies = torch.LongTensor(movie_dst)\n","movies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JaQV3McnhuP","outputId":"33a9bbee-3d07-4b3f-9eab-9fca8bb289ed"},"outputs":[{"data":{"text/plain":["tensor([[   10,    10,    10,  ...,    10,    10,    10],\n","        [  610,   612,   615,  ..., 10072, 10073, 10113]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["edge_index_candidates = torch.vstack([torch.LongTensor(len(movie_dst) * [user_id]), movies])\n","edge_index_candidates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXUqmmBqnhuP"},"outputs":[],"source":["with torch.no_grad():\n","    pred = model(test_graph_edge_index, edge_index_candidates).view(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Al1aG8jHnhuP","outputId":"fac34222-f7aa-43ab-c5ed-2fab7fbff5e8"},"outputs":[{"data":{"text/plain":["tensor([8961, 3505, 3505, 3505, 4595, 4122, 4122, 9131, 8212, 6183])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["ind = pred.topk(10).indices\n","movie_recommend = movies[ind] - num_users\n","movie_recommend"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvB9sRIEnhuQ"},"outputs":[],"source":["movie_inverse_mapping = {y: x for x,y in movie_mapping.items()}\n","final_id = [movie_inverse_mapping[i] for i in movie_recommend.numpy()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ag-3oe1rnhuQ","outputId":"a0ab7092-2be3-4e93-8424-e536eafdf0c7"},"outputs":[{"data":{"text/plain":["array(['Villain (1971)', 'Phantom of the Paradise (1974)',\n","       'Phantom of the Paradise (1974)', 'Phantom of the Paradise (1974)',\n","       'Alien Contamination (1980)', 'Android (1982)', 'Android (1982)',\n","       'Cosmic Scrat-tastrophe (2015)',\n","       \"Craig Ferguson: I'm Here To Help (2013)\",\n","       'Go for Zucker! (Alles auf Zucker!) (2004)'], dtype=object)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df1.title[final_id].values"]},{"cell_type":"markdown","metadata":{"id":"hbpxCW-lnhuQ"},"source":["我们还可以写一个接口来对外提供推荐结果。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m5hkL4DPnhuQ"},"outputs":[],"source":["def recommend(k=10):\n","    user_id = int(input(\"您想对哪位用户进行推荐？请输入用户编号:\\n\"))\n","    edge_index_candidates = torch.vstack([torch.LongTensor(len(movie_dst) * [user_id]), movies])\n","    with torch.no_grad():\n","        pred = model(test_graph_edge_index, edge_index_candidates).view(-1)\n","    ind = pred.topk(10).indices\n","    movie_recommend = movies[ind] - num_users\n","    final_id = [movie_inverse_mapping[i] for i in movie_recommend.numpy()]\n","    final_movies = df1.title[final_id].values\n","    print('为该用户推荐的评分最高的%s部电影是:'% k)\n","    for ii, m in enumerate(final_movies):\n","        print('%s 电影名: %s' % (ii+1, m))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pck3kBJCnhuQ","outputId":"554ddf0d-1f33-463a-a28c-7c84ed7bd3ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["您想对哪位用户进行推荐？请输入用户编号:\n","0\n","为该用户推荐的评分最高的10部电影是:\n","1 电影名: Villain (1971)\n","2 电影名: Phantom of the Paradise (1974)\n","3 电影名: Phantom of the Paradise (1974)\n","4 电影名: Phantom of the Paradise (1974)\n","5 电影名: Alien Contamination (1980)\n","6 电影名: Android (1982)\n","7 电影名: Android (1982)\n","8 电影名: Cosmic Scrat-tastrophe (2015)\n","9 电影名: Craig Ferguson: I'm Here To Help (2013)\n","10 电影名: Go for Zucker! (Alles auf Zucker!) (2004)\n"]}],"source":["recommend()"]},{"cell_type":"markdown","metadata":{"id":"zIsIDsHunhuQ"},"source":["## 3. 利用Heterogeneous GNN进行推荐"]},{"cell_type":"markdown","metadata":{"id":"x6WFNa7inhuQ"},"source":["上述的LightGCN将用户-电影二分图视为同质图，下面我们展示利用PyG中的异质图神经网络来完成该问题。"]},{"cell_type":"markdown","metadata":{"id":"Q-Qt3uGKnhuR"},"source":["我们可以直接使用PyG来加载Movielens图数据。数据我已经直接存在data目录下了，所以不需要下载就能直接加载数据集。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48pj9e8AnhuR"},"outputs":[],"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","import torch_geometric.transforms as T\n","from datasets import MovieLens, RandomLinkSplit\n","from torch_geometric.nn import SAGEConv, to_hetero\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","path = 'data/MovieLens'\n","dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')  # all-MiniLM-L6-v2表示一个transformer模型\n","data = dataset[0].to(device)"]},{"cell_type":"markdown","metadata":{"id":"faseU4n2nhuR"},"source":["值得注意的是，这里加载数据集的时候我们用到了transformer来提取电影的种类和标题的文本特征，并将其作为节点特征。"]},{"cell_type":"markdown","metadata":{"id":"TWc_0610nhuR"},"source":["接下来我们进行额外的预处理："]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gmpKkIbnhuR"},"outputs":[],"source":["# 添加用户节点的节点特征\n","data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n","del data['user'].num_nodes\n","\n","# 添加反向边('movie', 'rev_rates', 'user')\n","data = T.ToUndirected()(data)\n","del data['movie', 'rev_rates', 'user'].edge_label  # 去掉反向边的边标签 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"030Yt3oTnhuR","outputId":"d98101a9-4f7a-4b13-a939-b4631eba0190"},"outputs":[{"data":{"text/plain":["HeteroData(\n","  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n","  \u001b[1muser\u001b[0m={ x=[610, 610] },\n","  \u001b[1m(user, rates, movie)\u001b[0m={\n","    edge_index=[2, 100836],\n","    edge_label=[100836]\n","  },\n","  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"bnw5rQ8hnhuR"},"source":["然后我们划分数据集"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY5Z2VSBnhuR"},"outputs":[],"source":["train_data, val_data, test_data = RandomLinkSplit(\n","    num_val=0.1,\n","    num_test=0.1,\n","    neg_sampling_ratio=0.0,\n","    edge_types=[('user', 'rates', 'movie')],\n","    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",")(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opAMu91PnhuS","outputId":"400f3800-debd-4429-8658-c7b3f69c8a9e"},"outputs":[{"data":{"text/plain":["HeteroData(\n","  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n","  \u001b[1muser\u001b[0m={ x=[610, 610] },\n","  \u001b[1m(user, rates, movie)\u001b[0m={\n","    edge_index=[2, 80670],\n","    edge_label=[80670],\n","    edge_label_index=[2, 80670]\n","  },\n","  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80670] }\n",")"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"US9Q3sJInhuS","outputId":"527e3664-b547-4bda-aedb-01fee4165f85"},"outputs":[{"data":{"text/plain":["HeteroData(\n","  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n","  \u001b[1muser\u001b[0m={ x=[610, 610] },\n","  \u001b[1m(user, rates, movie)\u001b[0m={\n","    edge_index=[2, 80670],\n","    edge_label=[10083],\n","    edge_label_index=[2, 10083]\n","  },\n","  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80670] }\n",")"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["val_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0C5BlSNlnhuS","outputId":"937296c8-852a-4d9c-9311-862fc55f2c68"},"outputs":[{"data":{"text/plain":["HeteroData(\n","  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n","  \u001b[1muser\u001b[0m={ x=[610, 610] },\n","  \u001b[1m(user, rates, movie)\u001b[0m={\n","    edge_index=[2, 90753],\n","    edge_label=[10083],\n","    edge_label_index=[2, 10083]\n","  },\n","  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 90753] }\n",")"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lKUrOy6nhuS"},"outputs":[],"source":["# 同样地，我们使用加权MSE损失\n","weight = torch.bincount(train_data['user', 'movie'].edge_label)\n","weight = weight.max() / weight\n","\n","def weighted_mse_loss(pred, target, weight=None):\n","    weight = 1. if weight is None else weight[target].to(pred.dtype)\n","    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"]},{"cell_type":"markdown","metadata":{"id":"vXeIZq9DnhuS"},"source":["构建自编码器来完成预测评分的任务。这里我们使用`SAGEConv`（GraphSAGE）。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0adCqRtnhuS"},"outputs":[],"source":["class GNNEncoder(torch.nn.Module):\n","    def __init__(self, hidden_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n","        self.conv2 = SAGEConv((-1, -1), out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","\n","class EdgeDecoder(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super().__init__()\n","        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n","        self.lin2 = Linear(hidden_channels, 1)\n","\n","    def forward(self, z_dict, edge_label_index):\n","        row, col = edge_label_index\n","        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n","\n","        z = self.lin1(z).relu()\n","        z = self.lin2(z)\n","        return z.view(-1)\n","\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super().__init__()\n","        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n","        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum') # 将encoder变为能用于异质图的模型\n","        self.decoder = EdgeDecoder(hidden_channels)\n","\n","    def forward(self, x_dict, edge_index_dict, edge_label_index):\n","        z_dict = self.encoder(x_dict, edge_index_dict)\n","        return self.decoder(z_dict, edge_label_index)"]},{"cell_type":"markdown","metadata":{"id":"MUkZ5wypnhuS"},"source":["下面我们来训练这个模型。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHdyNkgnnhuS","outputId":"ed325b5f-4682-4e8b-813c-79487a37f100"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 020, Loss: 5.8017, Train: 1.2790, Val: 1.2948, Test: 1.2884\n","Epoch: 040, Loss: 4.3860, Train: 1.0836, Val: 1.0911, Test: 1.0893\n","Epoch: 060, Loss: 3.6048, Train: 1.1922, Val: 1.1923, Test: 1.1871\n","Epoch: 080, Loss: 3.2995, Train: 1.1425, Val: 1.1601, Test: 1.1529\n","Epoch: 100, Loss: 3.0741, Train: 1.1084, Val: 1.1450, Test: 1.1350\n","Epoch: 120, Loss: 2.9755, Train: 1.1073, Val: 1.1480, Test: 1.1385\n","Epoch: 140, Loss: 2.8910, Train: 1.1255, Val: 1.1668, Test: 1.1584\n","Epoch: 160, Loss: 2.7696, Train: 1.0441, Val: 1.0926, Test: 1.0821\n","Epoch: 180, Loss: 2.8414, Train: 1.0082, Val: 1.0639, Test: 1.0518\n","Epoch: 200, Loss: 2.5415, Train: 1.0646, Val: 1.1292, Test: 1.1188\n","Epoch: 220, Loss: 2.4486, Train: 1.0325, Val: 1.1076, Test: 1.0966\n","Epoch: 240, Loss: 2.3862, Train: 1.0159, Val: 1.0983, Test: 1.0863\n","Epoch: 260, Loss: 2.3625, Train: 1.0632, Val: 1.1456, Test: 1.1346\n","Epoch: 280, Loss: 2.3132, Train: 0.9968, Val: 1.0900, Test: 1.0756\n","Epoch: 300, Loss: 2.3369, Train: 0.9690, Val: 1.0653, Test: 1.0498\n"]}],"source":["model = Model(hidden_channels=32).to(device)\n","\n","with torch.no_grad():\n","    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    pred = model(train_data.x_dict, train_data.edge_index_dict,\n","                 train_data['user', 'movie'].edge_label_index)\n","    target = train_data['user', 'movie'].edge_label\n","    loss = weighted_mse_loss(pred, target, weight)\n","    loss.backward()\n","    optimizer.step()\n","    return float(loss)\n","\n","\n","@torch.no_grad()\n","def test(data):\n","    model.eval()\n","    pred = model(data.x_dict, data.edge_index_dict,\n","                 data['user', 'movie'].edge_label_index)\n","    pred = pred.clamp(min=0, max=5)\n","    target = data['user', 'movie'].edge_label.float()\n","    rmse = F.mse_loss(pred, target).sqrt()\n","    return float(rmse)\n","\n","\n","for epoch in range(1, 301):\n","    loss = train()\n","    train_rmse = test(train_data)\n","    val_rmse = test(val_data)\n","    test_rmse = test(test_data)\n","    if epoch % 20 == 0:\n","        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n","              f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"]}],"metadata":{"kernelspec":{"display_name":"gnn","language":"python","name":"gnn"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"Lecture8.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}