{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"gnn","language":"python","name":"gnn"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"Lecture 5.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Sno8E8x4RqR","executionInfo":{"status":"ok","timestamp":1638712899906,"user_tz":-240,"elapsed":2960,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"bed2d97b-c8ae-4819-bea3-f9cd3d72d4f3"},"source":["!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu113.html"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n","Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n","Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n","Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"iofLNj_N4M78"},"source":["# 第五课 图上的其他深度学习模型"]},{"cell_type":"markdown","metadata":{"id":"ovEEhTpK4M8C"},"source":["前面的课程中我们介绍了许多图神经网络模型。除了图神经网络，针对于图数据的深度学习模型还有很多，比如图上的自编码器、变分自编码器、循环神经网络和对抗生成网络等。在这一课中，我们对自编码器和变分自编码器进行代码实践。这其中包括了对模型细节和它们的应用的讲解。"]},{"cell_type":"markdown","metadata":{"id":"WB9RZjaP4M8C"},"source":["## 0. 链接预测数据集"]},{"cell_type":"markdown","metadata":{"id":"wujpszPM4M8D"},"source":["链接预测（link prediction）是常见的与图有关的任务。该任务旨在预测两个节点之间是否存在链接（link），即是否存在边。"]},{"cell_type":"markdown","metadata":{"id":"4Hyqe_mX4M8D"},"source":["关于链接预测的数据集，我们可以从节点分类任务的数据集直接构造。比如我们之前常用的Cora数据集，就可以无视掉它的节点标签，把Cora图里面的边当成训练/测试数据。下面我们具体来实践一下。"]},{"cell_type":"code","metadata":{"id":"ifKqMbfi4M8D","executionInfo":{"status":"ok","timestamp":1638712904050,"user_tz":-240,"elapsed":4147,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["from torch_geometric.datasets import Planetoid\n","import torch_geometric.transforms as T\n","import torch\n","import torch_geometric\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 构造一个transform，用于对数据的预处理\n","transform = T.Compose([\n","    T.NormalizeFeatures(),  # 对特征进行标准化\n","    T.ToDevice(device),    # 把数据放到cpu或者gpu上\n","    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,  # 这一步很关键，是在构造链接预测的数据集\n","                      split_labels=True, add_negative_train_samples=False),])\n","\n","\n","dataset = Planetoid('./', name='Cora', transform=transform)\n","train_data, val_data, test_data = dataset[0]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrVL4yei4M8E"},"source":["下面我们来看一下具体的数据长什么样：\n","* 我们不需要关注y, train_mask, val_mask, test_mask；这些是节点分类里需要用到的信息。\n","* pos_edge_label_index是正边样本的索引，pos_edge_label是其标签（全为1）\n","* neg_edge_label_index是负边样本的索引，neg_edge_label是其标签（全为0）"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdPkDwFn4M8F","executionInfo":{"status":"ok","timestamp":1638712904051,"user_tz":-240,"elapsed":41,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"2692990c-fb60-4ec3-dbfe-c450679c7ab0"},"source":["train_data"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Pm5_XsD4M8G","executionInfo":{"status":"ok","timestamp":1638712904051,"user_tz":-240,"elapsed":37,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"dd67ee6e-fc61-4298-b4a5-46a347c93377"},"source":["train_data.pos_edge_label, train_data.pos_edge_label_index"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'),\n"," tensor([[1256,  181, 1628,  ...,  484,  306, 2607],\n","         [2175, 1359, 1139,  ..., 1367,  487, 1003]], device='cuda:0'))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ojRXID8S4M8G","executionInfo":{"status":"ok","timestamp":1638712904052,"user_tz":-240,"elapsed":35,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"11140bab-633b-4e62-9a3c-6719c75fdb83"},"source":["val_data"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[263], pos_edge_label_index=[2, 263], neg_edge_label=[263], neg_edge_label_index=[2, 263])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"4TTXIjz14M8H","executionInfo":{"status":"ok","timestamp":1638712904053,"user_tz":-240,"elapsed":34,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"ff3925ba-89b2-40c9-d56a-8e91d0acb24d"},"source":["val_data.neg_edge_label"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       device='cuda:0')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gT3LGof84M8H","executionInfo":{"status":"ok","timestamp":1638712904053,"user_tz":-240,"elapsed":31,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"942880c9-79cf-4498-a3a8-c5d61e65c77f"},"source":["test_data "],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[527], pos_edge_label_index=[2, 527], neg_edge_label=[527], neg_edge_label_index=[2, 527])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"p_Ygvn4C4M8H"},"source":["值得注意的是：\n","* train_data中没有自带负边样本neg_edge_label_index，因为我们会在训练过程中自己采样负样本。\n","* train_data和val_data里面的图是一样的（edge_index是一样的），但是他们的pos_edge_label_index（正边样本）和neg_edge_label_index（负边样本）不一样。可以看到train_data中有4488个正边样本，而val_data中只有263个正边样本（二者比例是85:5）。\n","* test_data中的图和train_data的图不一样了。可以看到test_data中的edge_index要多一些（多527个），527也就是test_data中的正边样本数量。"]},{"cell_type":"markdown","metadata":{"id":"Z4ynTOjC4M8I"},"source":["## 1. 自编码器"]},{"cell_type":"markdown","metadata":{"id":"djf2aCzC4M8I"},"source":["针对于图数据的自编码器我们称之为GAE (Graph AutoEncoder)。其包含两个组成部分，编码器（encoder）和解码器（decoder）。图上的编码器常用的就是GCN了；而解码器呢通常用一个内积来表示。具体地，给定两个节点的节点表示，解码器将计算二者的内积，其结果作为两个节点之间存在边的概率。"]},{"cell_type":"code","metadata":{"id":"lfcsMpK74M8I","executionInfo":{"status":"ok","timestamp":1638712904054,"user_tz":-240,"elapsed":30,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["from torch_geometric.nn import GCNConv"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"08Zk3e6R4M8J"},"source":["首先构造编码器，由两层GCN组成。"]},{"cell_type":"code","metadata":{"id":"zHRbIher4M8J","executionInfo":{"status":"ok","timestamp":1638712904055,"user_tz":-240,"elapsed":31,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["class GCNEncoder(torch.nn.Module):\n","    \"\"\"GCN组成的编码器\"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n","        self.conv2 = GCNConv(2 * out_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        return self.conv2(x, edge_index)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TiqL0NdC4M8J"},"source":["然后构建解码器，将给定的节点对映射到[0，1]之间，以表示边存在的概率。"]},{"cell_type":"code","metadata":{"id":"En4QQbzg4M8J","executionInfo":{"status":"ok","timestamp":1638712904055,"user_tz":-240,"elapsed":30,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["class InnerProductDecoder(torch.nn.Module):\n","    \"\"\"解码器，用向量内积表示重建的图结构\"\"\"\n","    \n","    def forward(self, z, edge_index, sigmoid=True):\n","        \"\"\"\n","        参数说明：\n","        z: 节点表示\n","        edge_index: 边索引，也就是节点对\n","        \"\"\"\n","        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n","        return torch.sigmoid(value) if sigmoid else value"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ5bsyXT4M8J","executionInfo":{"status":"ok","timestamp":1638712904055,"user_tz":-240,"elapsed":30,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["class GAE(torch.nn.Module):\n","    \"\"\"图自编码器。\n","    \"\"\"\n","    def __init__(self, encoder, decoder=None):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = InnerProductDecoder()\n","\n","    def encode(self, *args, **kwargs): \n","        \"\"\"编码功能\"\"\"\n","        return self.encoder(*args, **kwargs)\n","\n","    def decode(self, *args, **kwargs):\n","        \"\"\"解码功能\"\"\"\n","        return self.decoder(*args, **kwargs)\n","\n","    def recon_loss(self, z, pos_edge_index, neg_edge_index=None):\n","        \"\"\"计算正边和负边的二值交叉熵\n","        \n","        参数说明\n","        ----\n","        z: 编码器的输出\n","        pos_edge_index: 正边的边索引\n","        neg_edge_index: 负边的边索引\n","        \"\"\"\n","        EPS = 1e-15 # EPS是一个很小的值，防止取对数的时候出现0值\n","\n","        pos_loss = -torch.log(\n","            self.decoder(z, pos_edge_index) + EPS).mean() # 正样本的损失函数\n","\n","        if neg_edge_index is None:\n","            neg_edge_index = torch_geometric.utils.negative_sampling(pos_edge_index, z.size(0)) # 负采样\n","        neg_loss = -torch.log(\n","            1 - self.decoder(z, neg_edge_index) + EPS).mean() # 负样本的损失函数\n","\n","        return pos_loss + neg_loss"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gr27seSx4M8K","executionInfo":{"status":"ok","timestamp":1638712904056,"user_tz":-240,"elapsed":31,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["in_channels, out_channels = dataset.num_features, 16\n","model = GAE(GCNEncoder(in_channels, out_channels))\n","model = model.to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAHxuCOx4M8K","executionInfo":{"status":"ok","timestamp":1638712904057,"user_tz":-240,"elapsed":32,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"e06f4908-a265-4b3e-ce67-e141e3a28904"},"source":["latent = model.encode(train_data.x, train_data.edge_index)\n","latent, latent.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-7.1088e-03, -8.9700e-03, -9.6406e-03,  ...,  1.6861e-02,\n","          -4.9310e-03, -1.5615e-02],\n","         [ 8.6641e-05, -2.0760e-03, -2.9901e-03,  ...,  5.7016e-04,\n","          -6.1729e-03, -8.0813e-04],\n","         [-2.3474e-03, -2.7843e-03, -5.1042e-03,  ...,  1.9495e-03,\n","          -3.7486e-03, -5.0528e-03],\n","         ...,\n","         [ 1.0891e-02, -5.0019e-03, -4.4132e-03,  ..., -3.5658e-03,\n","          -5.3808e-03,  8.0851e-04],\n","         [-1.0349e-03, -3.8962e-03, -1.1520e-03,  ..., -3.9173e-03,\n","          -5.8069e-03, -4.5615e-04],\n","         [-1.5305e-04, -1.9043e-03, -1.0611e-03,  ..., -4.7798e-03,\n","          -3.8623e-03,  1.9550e-04]], device='cuda:0', grad_fn=<AddBackward0>),\n"," torch.Size([2708, 16]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-Dvkhtj4M8K","executionInfo":{"status":"ok","timestamp":1638712904057,"user_tz":-240,"elapsed":29,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"1b3d8e9f-fdae-4359-8e1e-750d83c69df1"},"source":["model.decode(latent, train_data.edge_index)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.5001, 0.5000, 0.5000,  ..., 0.5000, 0.5001, 0.5002], device='cuda:0',\n","       grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"11j2zECQ4M8L"},"source":["## 2. 变分自编码器"]},{"cell_type":"markdown","metadata":{"id":"OB3Xma4j4M8L"},"source":["变分自编码器和自编码器基本结构相同，都是一个编码器加一个解码器。它们的主要区别是，变分自编码器编码后的隐层表示不再是连续的向量表示，而是通过一个高斯分布来表示。具体地，变分自编码器学习的是这个高斯分布的均值（下面用变量`mu`来表示）和标准差（下面用变量`std`来表示）。"]},{"cell_type":"code","metadata":{"id":"njaYTkkP4M8L","executionInfo":{"status":"ok","timestamp":1638712904058,"user_tz":-240,"elapsed":28,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["MAX_LOGSTD = 10\n","\n","class VariationalGCNEncoder(torch.nn.Module):\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n","        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n","        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n","    \n","class VGAE(GAE): \n","    \"\"\"变分自编码器。继承自GAE这个类，可以使用GAE里面定义的函数。\n","    \"\"\"\n","    \n","    def __init__(self, encoder, decoder=None):\n","        super().__init__(encoder, decoder)\n","\n","    def reparametrize(self, mu, logstd):\n","        if self.training:\n","            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n","        else:\n","            return mu\n","\n","    def encode(self, *args, **kwargs):\n","        \"\"\"编码功能\"\"\"\n","        self.__mu__, self.__logstd__ = self.encoder(*args, **kwargs) # 编码后的mu和std表示一个分布\n","        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD) # 这里把std最大值限制一下\n","        z = self.reparametrize(self.__mu__, self.__logstd__) # 进行reparametrization，这样才能够训练模型\n","        return z\n","\n","    def kl_loss(self, mu=None, logstd=None):\n","        \"\"\"我们给隐变量的分布加上（0，I）高斯变量的先验，即希望隐变量分布服从（0，I）的高斯分布\n","        这两个分布的差别用KL损失来衡量。\"\"\"\n","        mu = self.__mu__ if mu is None else mu\n","        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n","            max=MAX_LOGSTD)\n","        return -0.5 * torch.mean(\n","            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1)) # 两个高斯分布之间的KL损失"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEicQlOH4M8L"},"source":["（两个高斯分布的kl loss的公式可以参考该[链接](https://stats.stackexchange.com/questions/234757/how-to-use-kullback-leibler-divergence-if-mean-and-standard-deviation-of-of-two)）"]},{"cell_type":"code","metadata":{"id":"N4ndXaDN4M8L","executionInfo":{"status":"ok","timestamp":1638712904058,"user_tz":-240,"elapsed":27,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n","model = model.to(device)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z51OZqZM4M8M","executionInfo":{"status":"ok","timestamp":1638712904058,"user_tz":-240,"elapsed":27,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"0f697393-cd9c-42bb-9b8d-dee8789f232e"},"source":["latent = model.encode(train_data.x, train_data.edge_index)\n","latent, latent.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-1.8875,  1.0038, -2.1139,  ...,  0.4677,  0.9943,  0.2378],\n","         [ 0.9955,  0.3355,  0.4304,  ..., -1.5669, -0.4426,  0.4007],\n","         [ 2.0066, -0.5882, -0.5222,  ...,  2.1833, -0.6039, -2.2213],\n","         ...,\n","         [ 0.3537,  0.1473, -0.8227,  ..., -0.5180, -0.4414,  0.6746],\n","         [-1.1687, -0.9614,  1.2840,  ..., -0.6344,  0.4673,  0.9024],\n","         [-1.1162,  0.7176,  0.1490,  ..., -0.6302, -1.2232, -2.3135]],\n","        device='cuda:0', grad_fn=<AddBackward0>), torch.Size([2708, 16]))"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r8tKm3JI4M8M","executionInfo":{"status":"ok","timestamp":1638712904059,"user_tz":-240,"elapsed":26,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"bc303fa7-c28f-4d2f-b654-7c6c928ceae3"},"source":["model.decode(latent, train_data.edge_index)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0559, 0.0253, 0.8818,  ..., 0.9288, 0.2694, 0.2617], device='cuda:0',\n","       grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"vM73ztYW4M8M"},"source":["## 3. 训练自编码器和变分自编码器"]},{"cell_type":"markdown","metadata":{"id":"WFMxERHv4M8M"},"source":["接下来我们展示自编码器和变分自编码器的训练。"]},{"cell_type":"code","metadata":{"id":"iRKiP1nz4M8M","executionInfo":{"status":"ok","timestamp":1638712904059,"user_tz":-240,"elapsed":24,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["def train_gae(model):\n","    \"\"\"训练GAE模型\"\"\"\n","    model.train()\n","    optimizer.zero_grad()\n","    z = model.encode(train_data.x, train_data.edge_index)\n","    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","def train_vgae(model):\n","    \"\"\"训练VGAE模型，损失函数由重建损失和kl损失组成\"\"\"\n","    model.train()\n","    optimizer.zero_grad()\n","    z = model.encode(train_data.x, train_data.edge_index)\n","    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n","    loss = loss + (1 / train_data.num_nodes) * model.kl_loss() # 加上kl loss\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvuRT1bc4M8M","executionInfo":{"status":"ok","timestamp":1638712904059,"user_tz":-240,"elapsed":24,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":["@torch.no_grad()\n","def test(model, data):\n","    \"\"\"测试模型\"\"\"\n","    from sklearn.metrics import roc_auc_score, average_precision_score\n","    model.eval()\n","    pos_edge_index = data.pos_edge_label_index\n","    neg_edge_index = data.neg_edge_label_index\n","    \n","    z = model.encode(data.x, data.edge_index)\n","    pos_y = z.new_ones(pos_edge_index.size(1)) # 正样本标签\n","    neg_y = z.new_zeros(neg_edge_index.size(1)) # 负样本标签\n","    y = torch.cat([pos_y, neg_y], dim=0)\n","\n","    pos_pred = model.decoder(z, pos_edge_index)\n","    neg_pred = model.decoder(z, neg_edge_index) \n","    pred = torch.cat([pos_pred, neg_pred], dim=0)\n","\n","    y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n","\n","    return roc_auc_score(y, pred), average_precision_score(y, pred) # 计算AUC和AP"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtLmNwmy4M8N"},"source":["训练GAE："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GayvW0b14M8N","executionInfo":{"status":"ok","timestamp":1638712923938,"user_tz":-240,"elapsed":19903,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"7d0cea2a-6f37-4861-e036-722ba848916c"},"source":["model = GAE(GCNEncoder(in_channels, out_channels))\n","model = model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"," \n","\n","epochs = 2000\n","for epoch in range(1, epochs + 1):\n","    loss = train_gae(model)\n","    if epoch % 100 == 0:\n","        auc, ap = test(model, test_data)\n","        print('Epoch: {:03d}, Loss_train: {:.4f}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, loss, auc, ap))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 100, Loss_train: 0.9176, AUC: 0.9163, AP: 0.9254\n","Epoch: 200, Loss_train: 0.8826, AUC: 0.9223, AP: 0.9331\n","Epoch: 300, Loss_train: 0.8710, AUC: 0.9176, AP: 0.9296\n","Epoch: 400, Loss_train: 0.8556, AUC: 0.9257, AP: 0.9375\n","Epoch: 500, Loss_train: 0.8309, AUC: 0.9329, AP: 0.9449\n","Epoch: 600, Loss_train: 0.8150, AUC: 0.9398, AP: 0.9496\n","Epoch: 700, Loss_train: 0.8107, AUC: 0.9348, AP: 0.9466\n","Epoch: 800, Loss_train: 0.8108, AUC: 0.9346, AP: 0.9476\n","Epoch: 900, Loss_train: 0.8108, AUC: 0.9342, AP: 0.9492\n","Epoch: 1000, Loss_train: 0.7851, AUC: 0.9309, AP: 0.9487\n","Epoch: 1100, Loss_train: 0.8037, AUC: 0.9298, AP: 0.9481\n","Epoch: 1200, Loss_train: 0.7919, AUC: 0.9283, AP: 0.9470\n","Epoch: 1300, Loss_train: 0.7869, AUC: 0.9286, AP: 0.9462\n","Epoch: 1400, Loss_train: 0.7834, AUC: 0.9296, AP: 0.9462\n","Epoch: 1500, Loss_train: 0.7873, AUC: 0.9300, AP: 0.9477\n","Epoch: 1600, Loss_train: 0.7865, AUC: 0.9255, AP: 0.9458\n","Epoch: 1700, Loss_train: 0.7822, AUC: 0.9240, AP: 0.9438\n","Epoch: 1800, Loss_train: 0.7951, AUC: 0.9236, AP: 0.9441\n","Epoch: 1900, Loss_train: 0.7737, AUC: 0.9241, AP: 0.9436\n","Epoch: 2000, Loss_train: 0.7696, AUC: 0.9260, AP: 0.9457\n"]}]},{"cell_type":"markdown","metadata":{"id":"rjPkLKdK4M8N"},"source":["训练VGAE："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AeyMQlDJ4M8N","executionInfo":{"status":"ok","timestamp":1638712947054,"user_tz":-240,"elapsed":23130,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}},"outputId":"8d31a312-b158-49fa-c246-1a7b19563c0d"},"source":["model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n","model = model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"," \n","epochs = 2000\n","for epoch in range(1, epochs + 1):\n","    loss = train_vgae(model)\n","    if epoch % 100 == 0:\n","        auc, ap = test(model, test_data)\n","        print('Epoch: {:03d}, Loss_train: {:.4f}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, loss, auc, ap))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 100, Loss_train: 1.1583, AUC: 0.7794, AP: 0.7915\n","Epoch: 200, Loss_train: 0.9447, AUC: 0.9026, AP: 0.9028\n","Epoch: 300, Loss_train: 0.8988, AUC: 0.9201, AP: 0.9244\n","Epoch: 400, Loss_train: 0.8732, AUC: 0.9305, AP: 0.9360\n","Epoch: 500, Loss_train: 0.8605, AUC: 0.9358, AP: 0.9417\n","Epoch: 600, Loss_train: 0.8746, AUC: 0.9328, AP: 0.9366\n","Epoch: 700, Loss_train: 0.8559, AUC: 0.9317, AP: 0.9386\n","Epoch: 800, Loss_train: 0.8634, AUC: 0.9353, AP: 0.9442\n","Epoch: 900, Loss_train: 0.8655, AUC: 0.9325, AP: 0.9428\n","Epoch: 1000, Loss_train: 0.8399, AUC: 0.9357, AP: 0.9457\n","Epoch: 1100, Loss_train: 0.8517, AUC: 0.9379, AP: 0.9469\n","Epoch: 1200, Loss_train: 0.8432, AUC: 0.9365, AP: 0.9471\n","Epoch: 1300, Loss_train: 0.8461, AUC: 0.9329, AP: 0.9450\n","Epoch: 1400, Loss_train: 0.8452, AUC: 0.9362, AP: 0.9469\n","Epoch: 1500, Loss_train: 0.8295, AUC: 0.9336, AP: 0.9458\n","Epoch: 1600, Loss_train: 0.8498, AUC: 0.9340, AP: 0.9456\n","Epoch: 1700, Loss_train: 0.8414, AUC: 0.9320, AP: 0.9435\n","Epoch: 1800, Loss_train: 0.8257, AUC: 0.9346, AP: 0.9459\n","Epoch: 1900, Loss_train: 0.8327, AUC: 0.9359, AP: 0.9475\n","Epoch: 2000, Loss_train: 0.8207, AUC: 0.9358, AP: 0.9488\n"]}]},{"cell_type":"code","metadata":{"id":"nLWzgDz54M8N","executionInfo":{"status":"ok","timestamp":1638712947055,"user_tz":-240,"elapsed":19,"user":{"displayName":"Bo Peng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01149616516536783206"}}},"source":[""],"execution_count":22,"outputs":[]}]}