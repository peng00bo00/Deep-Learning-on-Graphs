{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 安装教程"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们推荐使用Anaconda来管理Python当中用到的各种工具包。首先我们在官网 https://www.anaconda.com/products/individual 里根据当前使用的计算机系统选择对应的版本下载。下载完毕后需要将存储Anaconda的路径加入到全局变量中"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用如下命令创建一个新的虚拟环境，名为torch，使用python 3.8\n",
    "\n",
    "`conda create --name gnn python=3.8 -y`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接着启动该虚拟环境\n",
    "\n",
    "`conda activate gnn`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "然后我们安装必要的工具包\n",
    "\n",
    "`pip install torch torchvision`\n",
    "\n",
    "`pip install matplotlib`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来我们需要将`gnn`这个虚拟环境加入到jupyter notebook的kernel中\n",
    "\n",
    "`conda install -c anaconda ipykernel`\n",
    "\n",
    "`python -m ipykernel install --user --name=gnn`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "启动jupyter notebook\n",
    "\n",
    "`jupyter notebook`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以看到一个kernel是`gnn`，意味着我们可以使用`gnn`这个虚拟环境的工具包了"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](figures/jupkernel.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 第二讲： 深度学习基础"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jupyter Notebook的安装\n",
    "请参考https://www.jianshu.com/p/91365f343585 第二部分（安装Jupyter Notebook）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 在开始之前需要确保我们安装了如下工具包\r\n",
    "# pytorch, torchvision, matplotlib\r\n",
    "# 导入必要的工具包\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. PyTorch基础\n",
    "PyTorch是当下非常火热的深度学习框架，其简洁的接口设计和详细的文档极大了降低了学习成本。不同于另一个热门深度学习框架TensorFlow, PyTorch基于动态图，也就是说，PyTorch每次前向计算的时候都会重新构建一个新的计算图。这个特性使得PyTorch更加直观，写代码的逻辑更加接近Python本身的风格，也更加便于debug。接下来我们介绍PyTorch的一些重要特性。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.1 Tensor对象\n",
    "PyTorch的核心是Tensor对象。Tensor是多维数组对象，可用于表示一维向量和高维矩阵。PyTorch提供了用于数组快速操作的各种API，并且用户可以使用GPU来加速涉及到Tensor的计算。Tensor对象和Numpy的ndarray对象非常相似，都是表示多维数组，而且许多API也类似。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 创建一个2x3的random tensor（可用于模型参数初始化）\r\n",
    "a = torch.randn((2, 3))\r\n",
    "print(a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.0680, -0.5468, -0.2516],\n",
      "        [ 1.1025, -0.3364, -0.1936]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "b = torch.ones((2, 3))\r\n",
    "print(b)\r\n",
    "print(a + b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[-0.0680,  0.4532,  0.7484],\n",
      "        [ 2.1025,  0.6636,  0.8064]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "a.add(b)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0680,  0.4532,  0.7484],\n",
       "        [ 2.1025,  0.6636,  0.8064]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "c = torch.ones((3, 2))\r\n",
    "print(c)\r\n",
    "print(a.mm(c))  # mm是matmul的意思，表示矩阵相乘，这里的到一个2x2的矩阵"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[-1.8664, -1.8664],\n",
      "        [ 0.5725,  0.5725]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# a.to('cpu') # 将该tensor放在cpu上；也可以不写这行代码，tensor默认放在cpu上的\r\n",
    "a.to('cuda') # 将该tensor放在gpu上；如果没有配置好cuda的话会报错"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.0680, -0.5468, -0.2516],\n",
       "        [ 1.1025, -0.3364, -0.1936]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2 PyTorch中的反向传播\n",
    "PyTorch的另一大特性就是可以对计算过程进行自动求导，便于反向转播。对tensor的每一个操作都会留下计算图，并保留求导的路径。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2.1 Autograd自动求导"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 首先我们创建一个能够计算梯度的tensor，记为a_（和前面的a区别开）\r\n",
    "a_ = torch.ones((2,2), requires_grad=True)\r\n",
    "a_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# 因为没有对a_进行任何操作，所以a_.grad是None\r\n",
    "a_.grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "b_ = a_ + 1\r\n",
    "b_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以看到b这个tensor里有一个grad_fn,这个grad_fn记录了创建b这个tensor的操作，这样便于之后反向传播（求导）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 定义一个变量sum_\r\n",
    "sum_ = b_.sum()\r\n",
    "sum_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(8., grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 然后我们反向传播\r\n",
    "sum_.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 接着我们就能直接得到a_的梯度了\r\n",
    "a_.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "值得注意的是，`backward()`函数调用一次之后会把涉及到的计算图清零，如果连续调用两次`backward()`，第二次`backward()就会报错"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2.2 PyTorch中的optimizer\n",
    "在0.2.1中我知道了可以通过`backward()`函数求得tensor的梯度，那么直接使用梯度下降就可以更新参数了。梯度下降有很多变种，比如SGD、Momentum梯度下降、Adam梯度下降，PyTorch已经在`torch.optim`中为我们实现好了这些优化方法，我们可以直接使用。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "param = nn.Parameter(torch.ones(2,2))\r\n",
    "optimizer0 = torch.optim.SGD([param], lr=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 我们自行定义一个损失函数，它是param里每个元素的平方和，所以当loss最小时（即0），param里的值全是0\r\n",
    "loss0 = (param**2).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 每次backward前我们需要调用zero_grad()来清空参数里的梯度，不然的话这个grad值会一直累积\r\n",
    "optimizer0.zero_grad() \r\n",
    "loss0.backward()\r\n",
    "optimizer0.step()\r\n",
    "print(param)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.8000, 0.8000],\n",
      "        [0.8000, 0.8000]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 我们也可以写一个循环来优化参数，如下\r\n",
    "for i in range(20):\r\n",
    "    optimizer0.zero_grad()\r\n",
    "    loss0 = (param**2).sum()\r\n",
    "    loss0.backward()\r\n",
    "    optimizer0.step()\r\n",
    "    print('loss value: {:.2f}'.format(loss0.item()))\r\n",
    "print('优化后的参数：', param)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss value: 2.56\n",
      "loss value: 1.64\n",
      "loss value: 1.05\n",
      "loss value: 0.67\n",
      "loss value: 0.43\n",
      "loss value: 0.27\n",
      "loss value: 0.18\n",
      "loss value: 0.11\n",
      "loss value: 0.07\n",
      "loss value: 0.05\n",
      "loss value: 0.03\n",
      "loss value: 0.02\n",
      "loss value: 0.01\n",
      "loss value: 0.01\n",
      "loss value: 0.00\n",
      "loss value: 0.00\n",
      "loss value: 0.00\n",
      "loss value: 0.00\n",
      "loss value: 0.00\n",
      "loss value: 0.00\n",
      "优化后的参数： Parameter containing:\n",
      "tensor([[0.0092, 0.0092],\n",
      "        [0.0092, 0.0092]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "从上面的例子我们可以看到，`loss`值在不断减小，而最后我们得到的`param`也非常接近于0。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 加载数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们以MNIST数据集为例展示PyTorch中如何加载数据。MNIST数据集包含了10种不同手写的数字，即0到9。每张图片的标签也就是0到9中的某个数字。在这个数据集上，我们的任务是预测图片对应哪个数字，所以这是一个分类问题。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torchvision`中收集了多种数据集，我们可以直接调用这个工具包来下载我们需要的数据。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "from torchvision import datasets, transforms\r\n",
    "\r\n",
    "# 下载MNIST数据集中的训练集，并保存到data文件夹\r\n",
    "data_train = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\r\n",
    "# 加载MNIST数据集中的测试集\r\n",
    "data_test = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里可能会有个warning，不过我们不需要管它。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`data_train`和`data_test`是`dataset.MNIST`的对象，我们可以按下标访问其中的内容，会得到形如`(data, label)`的数据。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "img, label = data_train[0] # 取出第一个数据（第一张图片）\r\n",
    "img.size() "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们不难发现每张图其实是一个三维的矩阵。注意，MNIST数据是单通道图片，所以`(1, 28, 28)`的第一维度是1。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 可视化前10个数据\r\n",
    "plt.figure(figsize=(10, 2))\r\n",
    "for i in range(10):\r\n",
    "    img, label = data_train[i]\r\n",
    "    img = img.numpy().squeeze() # 用squeeze()函数将img的size从（1，28，28）变成（28，28），从而方便可视化\r\n",
    "    plt.subplot(1, 10, i+1)\r\n",
    "    plt.imshow(img)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAABRCAYAAAAZ1Ej0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABDn0lEQVR4nO29d3hc13nn/zm3TJ/BYNB7BwGwN1HVkiLJslykyHJPbMt2fnbi2FlnN1nn5xQnu8lu+mazTlm3JHZcY1u2JKtZvVEUi9hBEiRI9DYDYDB97tx79o8BKVIiRZBEGYD38zx4SA7unXu+vOfc+55z3iKklNjY2NjY2NjY2Fw6ylI3wMbGxsbGxsZmuWIbUjY2NjY2NjY2l4ltSNnY2NjY2NjYXCa2IWVjY2NjY2Njc5nYhpSNjY2NjY2NzWViG1I2NjY2NjY2NpfJFRlSQoh3CCGOCiGOCyF+b74aVUjYGpc/K10f2BpXCitd40rXB7bGqxIp5WX9ACpwAmgGHMA+oOtyv68Qf2yNy/9npeuzNS5922yNtj5b48rSeKk/V7IidQ1wXErZK6XMAt8H7rmC7ytEbI3Ln5WuD2yNK4WVrnGl6wNb41WJdgXn1gADZ/17ENj2xoOEEJ8GPg2gom72ELiCSy4uLryYGARESKZJAHyMq1DjStE3+1EM+NYbj1spGq/mfgorX+NK0Tf7kT0WsTUWOmkSZGVGvNUxV2JIne+L31RvRkr5VeCrAAERktvEbVdwycVlTA4SYZQusYUd8ikMsnAValwp+gCelD8KcxXeQ7A1Fjr2WMyzUjRezf0UlrfGs9khn7roMVeytTcI1J3171pg+Aq+r+Bw4iZN6uyPbI3LjPPoc7CC9MHKv4dga1wJ2GNxZXA1aLxUrsSQ2gm0CSGahBAO4EPAg/PTrMIgQDEp4qRkApk3uG2Ny4yz9VnSAgixgvTByr+HYGtcCdhjcWVwNWi8VC57a09KmRNCfA54nLwX/zellIfmrWUFgCIUVskNvMYLpEgC/NDWuLw4W9/soJ9cSfpg5d9DsDWuBOyxuDK4GjReKlfiI4WU8hHgkXlqS0FSKqoopYod8ilm5OSfLXV7AISmoXg8iOIiLL+XXLEbAH0yiYgnkVNRrGQSmcvN6fsKUeN8clofwJPyR6NL3JwFYaXfQ7A1LjRqcTGUl5Ar8WI5VZS0iRZNIXv7sbIGWOYVX8MeiyuDlaBRLS7Gaq4GQJgSjp3CSiYv67uuyJCyWRqU4mKyq+sYvsmFtTbG3236LiaC/7Ln/Sj7Sqh5sRT9UD9mOLLUTbWxsVkmJG5so/89kt+58THe6e3me9HNfGPf9az6H3Woo2HMqamlbqKNzbyRvLYV3xcHUYQklnXi+p0G2Nd9Wd+1/A0pIRAOB0JVz/28rYF0pRepCSxdkPGrBPrT6Pt6SV/TRqJSJ1YvkCoIE3wDEt9QFterPZgzM0uj5WIoKlpVBcm1NfS9W6GiZYy3VZ6gyxHBlHBP2wGe87VyoqKE9mQ1rGBDSqutwSwLMnJzEe6wRcmTJ7FmYpc9oygE1GARmc2txOocxBoECFDTUPfYNMrENLmhq9qfszA5/fzRNITDgdVYjenVMV0qruEY1rHeOa8MLxmKilpcxEydxubOY2x191KtObnZ183Py1aTrQjijCVhGRtSQtNQSkIIIUBVMcuLyZa4GNvqxHJynpizc3GPSdwRi8Bjh7HicZAXOWGpUVS06kqskJ/w5mK84zmcP9+51K0qCBSXi/QtaxnbqvP+8oPsiDYxNBPAZV7+PV3ehpSiIlQVxe9DOJ3n/Gp8c5DJNRLLZYHbpK56gsGXqmgaLqH/Dp26DcP8vOO7FCkuolaaDx/7EKd21dJ+ohgK1JASuobRUMbYFp2H3v03VKgWfsUB5LX/t/KdREtfYrhT4ze2/ycCK3jcZJvKmex08Zuf+Sn/cuo6zCNlKAMSlrEhJULFDNzhoHVbHy+1P4QuVHZnsnxm4j8ROqwjbEOq4BAOR/7543YjPS4mrgmQDgmyQUnp3hDBU4NIS87LtthCoTh0KC8h3iD5o7qHadAkCg6ucUrWhEY4UFmOY8yz1M28IoTTiVVdhtQVpKYQXuch1gSPfegvadF9GPKt78/vjm7jsROdBHcWI9MZpJFdpJZfBoqK0DWyjWVEW9zU3N/LvkMNtP98qRtWGAi/n767VBq6hvig/wh7ZhqYmvRRYVz+e7/gDSnF5UIpLQFNRWoqybZS0iGVWIOC6QTLKXF1TFMfnD7nvFsCr9DiGkcXJiYKUdPNQzfA0eIK7rpxD/eGdpGWkr6syXOJtRzvqaL0CMhk6vwNWWLU1iYyDSFGP5vml+p3U6uBjg7ApJnBABKWgleR1Go5Yg0KwQ1d+X3fdGbBH+SK14u1uhnTk5+Ne/b2kxsdW7DrxWudJGrhyUgnY+NFFFHAD7aLoagYt29ktMvB++58kbf5j2JhYUgwEQgJotBnwFcRakU5lAQZfEcp6TKJWZumJBSn2jfD7YHjFKkp/Gqab3Zcx0DDBuofDGMePrbUzb4gMpdDTEbxjJTxf8Zu49fLn2GdY6lbdeVolRXIkiDj14dIVAtcmybRtSyqYnF96RFWeUapUDXMfAThW3J/6CW6PMP81WfvIdhdQ9mPD2Gl0gVpUCkOHVEU4OjHde7ZtJMN3n66RyvQKiuW/ar9lZK4bxuTHSofufkFrvGeIC0le8Zq8Rx2IRKX/74qaENK6A6UkhDpVZVYuoKlCyY7NdIlEveqKQLOLAFHht9vepjrnBc2FMJmih/FVlPvn2K6ycUqzyh+Jc2uTCVH01U8Pb4K95CGbzgLmcwiKrwIQiBUFaFpZBpCTK5y8tnOJ7jJ04NH5J90FhbTlsKk5aInW0mHY4SNTotktUm0I0BxtAwxPbPg/g3C5SRR5yHrUzC8AvcJLyygK2k2IMgWSSJpLzKlwTI2pISqEqvRiTda3B/aTpkiMKWGIsCSV1RXfPGYnQUrHg84dITDAaqC1M7acp+egVwOaVoITQNNQ84GRchCGnfnQegOhMuJ8LjJNVeRrHaR3JyiqTLM3ZX72eY5zio9hyUlihC4hEa6ReNryRvJ7vChHdMKdotPmiYymcIxIzk8VcF0qZvlPJ5OI0uCJJqLmFxvEayf5o87H8IlDFRh0aVHKVXdgI6FxOKtjalOh0KpeozvbRxm0Kqm3O9DmGZBGlKoKsLhYG37AH9RuZ2DWUnAm0b6vYh0Gq5eO4pok4qxOsmHg69SpJhMWhrTk14qBi1kOn3Z31uwhpTQHbC+nf5bAnzhUz+hUp8mqCTxK1l0LPxKvuOrQJHimP3bm7GweCFdwz/+8F1oCdDS8PXn3sXXAVdEoqUsnFGTxt4R5OAIZqE80IXIR+bVVJJqKmbiMyl+bdVTvN9/BJ/QzxxmSslzyTYem1jD8UdacNwQYfvmf+exe/6WPXfW8oc/+xChA9UEv719YZsb8DOxQSFbYqIXZzAOFKH0LNDFFJV0SKBXJthS0s9AOJg3OsVbZvEvXBRBulRAaZqgAk5RsMPygmg1VWRayxm+wUWqzmB9Rz+rAmPc5j+EKiymTS9ffOgjeIYUXJOSZIUgWWdS/oog0JtC2dldmC8lyBuHrfWENxcT3mbyrs37uKt4Hx16GI8Aj6Jy0lDYng4ymivCr6S5yxPmHv9+mjdP8N/X/irV4y1YR08UpjElJVY8jmvaYmg8yERTAAgvdauumKHbS3DcEeYfO35GlyNCkaKizhbk0IXzIme/mTLVybdXfYfPOe4j+kwdnqMaViIx382eVzRU1jhMmoIRpirqcCTTMB1d6mYtDUKQqLO4raWHMtWi13DztfGbKd7hoPin+zGvYKWuoJ/YwjBBQIdzmGYteWYGcT4sLI4bOdJSJSEdNGpxShUHBiaD2RKKj1joCQsll98iEZbEMZVBZAxEMgPhSawrsEjnG7UoQOradmbqNWaa4V0Ne7nJcwyf0NHFuUZjtT5FsTOJloSZmIfXMgqtOmx1DWBWZsgMuha8vdLtJNeUxu0yUFULqS7MNYXuQHG7SFWbbKoeZjLrxYg7UKJTVzSjWCrU4mIoLSbRaNJePY6OIC4NIqbg65FreWG0Be9oDjWaohC9bITTiVJXzczacsLrVJR1UTaWjXNfxR5K1DgBJY1HMShTE1SuHmesKkAsruMMpukoi3B8pgHT4aF0n15YhpSiojh05JpWUhVuIl068ZYc6zv7uLt4D1udUTyKk7TMMWmafD18C88PNWMYGpXBGW7v/D5BBTocYxheML0OhCjQ1UUhEJpOzilwebJ4lAKZTF4higHJjE5IjVOh5g2ntMyRtEx2ZEoZNYpQhMSS507A2pyjlKkJVulvnpyXqU6KnUmmNQFKgd7Ps1CFgoqCQzFBFbBcJ5tvQPF6UYJFZJvKsZwqzp09b5ny53RqD6UsTbt3lAlT4eVkG08f6qB+yLxig7hgDSmZM1BGI7giQU5kywkp/ZSef9EJgKRl8L3pbYyki5jI+Phg5U7u9PSTlJJD8WqKHj7wpv8syUWDNZaOmkpGPpnmnrYD/Lfy017jbx4EqhDc6YmStA6yy70WM6bzldHb+K2qX1CtZqivnGS0tGrBm5sLuvn8xmfoTlTx8lDTgl1H8bqhvJQN63v5u4af8v5DH8c14MA8dmLBrrmQWM3VTHf4+cgNL/ErwR04hUaPIXgu0cGzX91GxbMTMHIUq1BWSt+AWhxk7JZKpm5J863rv0GbnqJIcaCgsDsDXxm9jRr3NFWOab7f9S3K1NdXAhQUPut5G0/Xt1P2cy8U0OxecbtQioMc/ZCPUGeEb3f9OxWqQehM+/MTurBp8myylace2kzTjyNI3SS8qZrkH5uEVCc+ITH8EiPgwKEU5ktMqCpKsIhUmcKWmn5qtGkutMK/nPAP5Rg7HGB0XRHrHflVmKhl0msE+MODd5MY8r9+8OyLQKqS9lXDbAgN8odlr7xp0mpTGIjqCmJdpQy+N0dxKEb571ejDIxd0IXFaqlh7JoA1zcd5GbvEXan6/i349to/ZaJ48QIV7pOXLCGFFIiozMU9Wb48nP3UtMQYUPJEAenqih1x/nXpodxzm5xvZa1eDnZxQM/uAnXpERNw5/VNfOHlSbtXYOcGC2j1TyyxILmiBBoDXXMrAryrpad3OrvRpmt5JOUWR5O1HIoWcOL4y38WsMLfNA/wmAuw8FULd4hCzWtsT3ZwdvuOkad9xhCSOQiPb91YaKKhTVNM5taGbzNwedKdmFImJjy4y3MIMu3RA0EkI3V9N9ZhHrNFLf6D1Oi5v/vHoxu4ju7t9F0IgvjkbxTq1lA61GzvntKYx3xzjL0+8b5WHU3DVqSV9LldKdr+NqBG2DERfCI4JBTkPPArl9u5K6SA9zrHTnzguqeqkCMuKDQtrxa64m2BWjf3M99lXuo1nI4z3qpGtLksKHyf8fewfafr6NqRxbGwoiK0gKenV0AoSBcTnIeWO0bwa8YnDakKp0zvNSg4AoHcE9VYIYjhbk9eR583RH0eJAvGvfzn/35m6LkQM0IgscsSiffPKakgMjuOh5orePuD+6hQUueMf6TlsG/RNfwwolW2o9PIaeWzxaZIixMpwpq4a+izYWZdWWMvjfL+7tew6UYPFt/A960ccEUHTMtPrK3RXln6AAOLP5k13twH3DjONGHNTV9xe0pXEMKsNJpnH0Ryl+sZnyygkdqgjh7XfSXmEw35AgpCrpQOZCu47Gx1TT8ZBw5MIyVTFLWWI9RE6LnvjrUtEAuh6in2SX2bF0JM/Uq7y/eSYOWAtwY0iRqmTwaWcve0RpyB4p4wr+Gd3r7OJQt5/BMJd4RA9eUgnNao+eWCnRfDw7FRKqAoi5c5J4QSEWgYqEs8FtkpsFB5429bHX3YiAwpx3o8WVwb9+ACPiJNweQm2b4+7U/YI0jhkfoGJjsjDQQ3OPA1TdakEkQhaajuF2km0uY7NT4dsd3zxgar8RbeXqkndKfuwicTKHsPoLidCKKi3hlQyOlzjj3eIewZldXx6d9uMcFFJKhCKSqfUy1q/x2zYu82xshX18375NoYRGzcuxMtfFcbyvtPxiD8TBmdAa1vITlEh9wBkWApmLpUKFHcZ01GSrXZ0hWWyQHdVwjQcR0dNkYUubxU+gnVZpPVCL1/KtOmBaYJtZE5ILRa56SEL5rWzj13jKCyiBls/ZzQlo8PtaF0u9CDhzNR0MXOKcjEnVhYToUeGO+xWVKrFblv256nDs8xxgz3Txa+jZc4xdI0SEEiSqFz3Y+z/XuAaYtDe9rbkoOZskNDs1LewrakAIwB0coeSxJya4gls+FGpkk3VTCvU2f5N76ffxuyWH+Yt/bce72UTfejZXKpy8wh0ZRI1N0jJSAZZHLFpD/xQXQ6msxakuIf2mGT9Q/wyo9g1M4sLD45+kOHh1bTfZ/VVFqSuLVklef62RreSvlz+n4BzI4d/eAIvA4nRz6RBWecp3fb3qY/5p5H2zpQusfn/+UBEKgdrQy1eJmk/sU4Zz/4udcAZYO1Z4oHsUgZukU71cpPrL8fKOMulIG7oT3NR9iozOBSzgYMzP8c+R6enfW0f6TXszJwjOiAKxrugh3uWm//wi/XraHJt1iezrEg1MbefnbmyjflUA70YuMJ7CyWXKbO5js8vDJNU/z4aLd6MLJmJmh1wjgetVHzVNTWPHC2dYDmGrX8VwfpkWf4HRt98FchiNGKY9OrWd3uBbre+U0nUxj9Q0ijRwIhVR9EakKgbqMfFFkNos5OELocCV/8vLd6Dc8wAd84wC819dN27tG+Wzpr5IpKqE6Mo01ukzGm2UiLRNzaDRvLJ75XCJzxvnPUVSS17QwsU6nzTFKmfp6NJ8hYXC6CEdU5N8zy2FyPkute4pXOzRc4QD0LnVrrhzFhLDhJz07azEdIHX1Tc4viseDXNVEotbiJk8PRYrKpCkwHWDp8zfjKXhDShpZzIkJlFgMxeEgF0/gdDmIhP0MVhTPHiQQFiCtM51bGlmkkcWKxZau8XNFUVFcToyaENOtbu6rfYn3+g8CCnFpkLYkL062cLyvgq5DY3mHQaUMITWMEQcluyMwOvF6RnYhyJl16EKlQ0/QXjzOsbYuQvEimHdDSiFb4SddKihRMjiVCzyg5uNSugPTKShzxNCxSEod15REi6YuErxcWAhNIxN0UNc8wQZvPx7hICMNhnNuHh/swDskyI0UXhkyxetFVJUz3uVmcr3F/RUvstUZ5WDWxQOTm/jFkU4aD2fQDp7EjMXOjMVktYtoG6z39FGt5bdJjmSL+fHkFnzDFmI4jFVgK1JaWjI94+HZ5CpO5cIMGcX0pCo4Eq3g2EAF6qiT1r1TiLHJM5G+QtMwvAo5z/J5wQJ5Nwoji2c4ja/by8ktZTBrSIVUJze7k5QWx4gVuUEr+FfGm5hrEIMaCCCKAow36aRqTYJKFv2sV3NSqqSGfJSMy8I3oqQkZynkMNFQKVJTZIMS06Uta+834XSi1lSRKYZSPUZGqoybfrQ0KFnz3P0QIRB+HzNtfqzyLCElR9SCU7kyHFHQ4/O3srpsRoWVTsPpqKyciUyqzBj5yLCPrd7BA751iB/4IDpT+J38DagBH7KxhsFf8uLcOsntvkMUKSrHDZVTRinHMxXs39FK2UGwwpNY8TjOUwO4FAFCwcwZF9RcpDh4b+ke/uC+OtRsMb7D89t2oapMbHARW5OhVFXxKAuz8id0B2plOelSuNXXTZkqmbBU3GEDZTK2fAwpRUUtLWG6Vee51d9FR8WQMJCzeDC6Ee2HJZR1zxSkm43saubYh73cedNr/Fnl03gUnV0ZF5/Y8Qk82710/qQPKxzBfEP05NgWhd969yOsd4Q5nYX/b/ruJPL9Osp3jWJOTCyBmrem8sGTlL9SzD+/951YDkn5bgtX2MAxMkNH+BTW7GrbOeNOKGQCCoZfstx29wDEK/up2ePguXe08cWSQ0vdnEXH2NhCeLUb8Y4Id9ecoFpVz3E2H8oFaPv3JGrPYEFG0J5BSsjliGa8DOcy1GpuSrUZspUGhm95G1JqTRXHPlNF2zWn+Ii/l6dTIR6a3EjwSBzl1Og590XxeDAbKoi8L8H72w5Qpjr5l2gjD4xspOqJEayB4Xl7zi4bQ+ocojFKd5bzkruFJ8pfock5wQ1VJzncthanEOQGBpe6hXNHUZG1VQzeHoQNM9zdeACPyPFaxsdvH/wA0SkvSlgndAh8Q1nk6Ye3NJlDQl4UFPxKipqiKNOuwAK0X5AtAm9RGhVB2PATn/RQlZnflSm1pJjxO+ow25I0aDNMmAqH0zWoqRzSWLhVsPlE8ftRSooZek8tsWtSeGa3bdMyx9cjN/LzE6tp6Emgjk5dcRTJfCKcTnLXr2Zig4v1W3q4regwulB4PFnEA5HNeF/0EurOYE1OYWXz90JoGkpRAFlTTq4iy1rXAF6hMJzL8JXw2+g5VEProSQUqMOuNRNDWBYVu/xYmsB3Iooyk0RGY1ix2Pn9hBRBukyglKZ58ybDMkBKZDaLJQUKAgt5JtBlJSJ0B2J1K+lKL1PtOjMtFu7aKB9oOMB6T/852o8bOXYlm1GSRv4ZXMDIbBaZTDEWqebpZCsf9J/K/0JwvsDvZYMaCGBUBSlZO8GNJScwkfyf/ts4cbiazvDYuT5vikrqli4iXTrvanmFjZ4++nJZ/mrP2/HsdVM3dWRe7+OyNKTMiQhlP06Tc6/he6uu5beqfkFbySif6dxKiSxHHRxaNqtSikMn2RSg8q4BPlX7Ivf6xhnOWTwT78Txo2Ja+tM4jveD05FfrjUu/RUbVFI0+iPsdtbNe/uFEGSDFs1FMygoDGeK0Md11FRyXleJrNJi4nfFeX/rPuo1D79Iudkda0RNZCG1PHw2lFCQTFMpHR86wi+Xvnbm84y0+Gn3ejz73Ijdu8gVUj4lQPF5GbzViWdDhB+0PEZGGkxbOb4/vo3t3S10/uAoViz+eooGIfK1LytKiWwspq56lC5HDI/iYGfGwwPbt1KxXSBe3lewM3srkYBEAtdD+S0ua/bnrRCqSrLSorEigrKMfKTeiCIkqlBAWlgFuTZ6mbzhnihuF+NbiphcK/mt2x/hWvcJVukZPMrpXIX5400p2Zlu4JWpJkTWKKwI2vMgc7m8m8ewi0fr13CPb3mmhjkHIRAlxcTrXHyp7Ye06WEyUtK3o5aG53NYw6Pn5IFUHDqDt2hUrxvhjypeImyaHMhWUvkzB77/eHnenzvL0pDCMrGSSSq2RzmS7eRfP5PmN8ueoelDPRwerUTcch2uMLgiFsVPnijIrQPIz4hkZwuTnRp/1/gIbXqUmCX4pSe/gP+Qg7qXhpEzMcxYHHE62qKAi58CnIqVEDgOyszlG1JC0/JFYNvrSdZ6mdioka7P8idrf8oG1yDg4Pe77yG+r4TWsd4ryki7mCS6Kpns0vl02W6udQ0Bbh5PFvFkdDUlv3AROhi9sBPsEqF4PFBRSuvbTnFvRd74ezhRxeNTa+j5Rgdt3UmsaOxMu7XKCsyqUo5+woe7Js4djTt5T/A1dAT/I7yBB0+tpemBHM6+yYI1oi6GcftmEtUOTAcg8iHzQoKlQcmqMFtK+lERHMxKnkt0EDwK7kNDlzUJWgosKTBXgBGlFhcjiouIXFdJskIh3mwilbM0OSzetX4P63wD3OLpma0qkDeiTCkJW1n+T/gmfnxgI95DLnyDFsWjhws2p9tKRauqxKoIcfgzPtrbB9ngHOeR+Cq+O3AN5butfF3Xs+6JdeMGwqvd3HzTAd5fuhMdlW9MbuN7O7fRPrAwtXSXpyFF3upW+0coz+Z45e4G3hEs4dPVz7OvuJ4HfOsZGwmij+sED5WgGlmseCI/kyiglSqha8SbfCSrLW50pUlLlcEcFO1zUL47Se7UwBnD6XJafXp5Hljw/E6nSRgOnDMWZM9jEMzWY4P8SpZwu/PRNMqskagIhMeNdOhYPifTHX5i9QqODVNcWznIHZ5TFCkOLCSTQ0HKj4IVixd8OPZpwzBWpxFvNFntGCWkaEStNC/EtvB0fzvVx5IoPQOYBdQ/AYRDx/I4uKvsMDd5TmDhYGe8iZdONtO6YxLr2EkUn/dMfb1sQynxehc3X3OIO4sPcu+s03JaCl6caGHmZJCq/SewZpZR8i8hEI58Rn3h9TLW5STeYGG5JFLI/MKFBBS4vXSYFtc4hrQ4kKnnoZG1eEcNcmMTBT8JOpvTz42L1aArSGbTyFBdTrLWT2SdQNameGf74XOCYXxahi+EduJTnFicW6U5I3MM59y8MNpC0U4XZa8l0Qcj5OKJgnqHzBVVSFDkskrNIbR87c5cQzkzzR5+aeNBPlK2nQrVSTjnZ3CsmMaY+XpFC5H3GY7Xu5jqkry3dBfbnFOELYvt4SaC+3XUyYWZwC1bQwrAnJxCRGdwf3szX1x9P3/xK//K+wKv8StrXiOzGiKWkw/5P0dRd4jqR4eRU9GCysujFAdJ3D/NxxoOoKDwaKKaB8MbqHg1jth9BHkFD96zl+cXE6+eJVKkgOPNpXy0hlpyFUVIRWAEHEys1/NZn/0SNIl0m3z2mmeo0KI4hImJgiFVHgmvBSAmBbo08AuBe1Cj+EgMeT6DrcBQ2puZ2hCi7EP9/E3Do9RqcNRQ+PbkjTzxk2uofySKOHa8MFfWNA3LqbHKOUytmr+nD2zfSut30ohkGta00feOIpINOVrbRri1bDtd7iGud43hESqnEzsmLZOBV2uo3CuxpqOFVQ7mLVA8HoTfh9FWzfA2D/LGaT7f8VNuch9HFRKVvGP56VFWpAgMKTlg+PjTPe+k8WsKjoN9mMvIiFruqMEgVmstR+738NEbX+Qu/37K1BR+RbzJ48unnL+U1bAp+OuhO5l5qZzGbx3ESqXJmeayMobPxq+k8BalMR2+pW7KnBCahtLSyNgtZej3TPD3nd+gTTPwKDoKCtd4TtC3qoQn712Nb91q6r59HDIZRFGAyDrBHdftpVmbpCen81vdHyb5VDm13zp4wdxhV8qyNqSQEpnL4e+NAz7+5Mi72VbZz6+UvEyDlqRLN2nrHOKYqxLPeAX+kz6U7ixWKr3kA0KtKMdoKGNr5TG2ePOJPfYn69g7UkPjTBrzCl80p+tHWUgS0sGpeAh1gd5dwoKclX9ErSse4sfra5BKFZ5wxTnHxWpUMiX5rRDTJVGbYnicBn5XhpShoyoWSdPJSbOcsWyAU/EQEwkfkVPF4Df4XMVT+EUWU0r0OKjhmfzDrVBRVBSvh9iqYkZvtHh/eTer9Bl0HMQsF73xUlwRiTI4nt8uKNSZrpQkpZOMjOIROkV1UUZuDKEYXgwfsGGG9WUTvKPsIB3OEcrUBFkp0bHQhUrSMpiwNLxDAl9/ouC2L9+EEKh+P8LvI3ptHalShUQN5FqT3FN/hNXOQfyKxVGjiKCSolPPl2o67ZwctzJYUkFRLAyvA6dDz8+WC/X+rjRUBcuhgs9go6ePVj1NkeI+76HKGe/rc00sjzBp942zr6gNEQoixsPLxvg/H+VqjK7yUU5525e6KRdFaBpKcwMza0uYvDbLp2oPstGhoAsPGWkwYqZwKSpbAyfpby+mt6iUyHgLwpRkAwLnqijXBfJ+YQfSdUzvLKfiWO719EALwPI2pGaRuw/hP+jE19fO9q2bGP+Qj49VvsxdnhgPd/yMV5sE93s+SXxngJrpcpSR8SWv2p1ZU0d4jZMvlrzKJkcMC53nxlphbwAR65+Xaxgyb2QMGCUcHaygZmZhjA5hCNI5DQuL3y17kY++Zzuv3N7MuHFulODtvkNsdr6+5ZiRBklpMm3Bw7G1HIjX8K3922DCif+kQvGxLGW9k5SNdZPZ0sbQ9UGCyjgeTFwRSe5k34LomS8Uh46orWT4ZsGxe/5x9tP8A33a8nAiXEIwYhWsDx8AuRxKJkdPpoI2fYJWBV7d8h3Ycv5tn31ZGMgFGQDK1BhrHDBhSY5kKyh7LQGv7F98DZfC7LaQrK8m0RRg1e8e4pPlz7PRkSMjc8SkxXDOzcvpGv6p7xaa/RH+oOoxgopylpMy6CJHa0WYE9c20DQaQoQjSNu3ZtFRsC4YQakg8qv2gCXPfTbWam7+pPw1XlzfwuT11YReklh9BbhiPEfWOAz+tO5B3lvxuxQvdWMugnC7Gb+pnMh1Bofu+KfZ5LbKbHWPLM8mG2l3jPHxQB8fD/QRbc/yD6uvwSlybPKcok2PUKU66DY0fj6xlqa/3Lfg7/sVYUgBSCOH1j9OOdBrtfGFjla+3DjN19d9iwYty2+se54fBjdxvKySlh+6Ye88J1S6RCxdwdLBK7KYSPpyWYZPldLwmoG8zCSiQtMQa9qJrC/ipuIdJGWWB+IN/OOJm6l42ImvOzzv+8NW1qD+iSxTp8q5U3yEOv80zZ4wE1k/KfPc7b1ozs3TWpJHhlczGfeQmnSjTWs4IyK/wpSW1ERMtGQOx2QaNTyDjMXJbGljYqOTNj2MieBg1omaLfzZvVJawsBdZQRbwm8yOl6KteF4pgh/b7SgXXqtRAp1dIqvPfh2vrt6Kz/Z8HVCqopHOOjOWpwwyviPiS0cnqgg3h9AjylIFd5x+y6u9x9njWOch2Nr+cngBvzxTEF73AhNQy0tIdtaRf873IQ2j/PB0h2kpc4Hjr+LU5MhEuNe3EMaehz0uOTZzirufPcBNjiHaZhd1HAKjQYtyf01L/GLO6K8Gl5PubsLbc+xglgNnwtvTH/QGgzzUkMI6XZe5MylR8YT6KfGqXi8nt8d+DjedZM4NJOxgWKwBMI8y7A6/VcJwfppNpYP8aWqx6jXzr+CtZzwjAr2DdSSbJC4lkkQqbKug3hLEdp9E/xK9VEMTCZNk0lL46N7P8HMuA9tUsO1KsrnO57lDs8xylSNt/sPoAuTMiVDUFFQhaBazXBfxR7+8C/fR2iPQsXj/VjhyDnRffPFijGksExyo2OIyBSVJ4sIbGlkqiNET0cF63xhPl/cwyrXMN8puo7hl1px7l/A2nNzQKogNXCJHIaUDOcCuEY1vIcGMROXEVmgqCg+L9E2PxM35FjrHSRpmTwRWU3kWAmrnji6MGU4LBPt6d1U9dbTW17LcE0Jp+pC5z30OKUYpkLq1VLc45KKUwbu/jBmd8+bjpVAjnxkY7TFQawlR7UmGMwJDmVqUY1CNj/I1x8s8hHfkOadlX3nOJEbmHTPVFKxPYoyOFHQ0WvSyGKGIzQ8WsFQIsSBrnLqtSmKlBSvpFaxc6aJHftaKerWaH8lhhJPkwt66N5aSZt7HBhnV7SBoZOldKbCSy3nwgiB4vFglRcz2eWm5YY+Hmj/GYY0eTxZzpFdDfj6FBp7DDx7T2CGI6i11SBrOHlHOY16mAbyhW0B/IrKuz0T3ON9lo41nWhJF5X9IcRUFPP0ODzbf7GAtv3Ol/6gyzdCd0050u0o+G1KK53GGhom9LRJcH8xgzMlZFRofjWDkjFRcuc350euL+Hp1X4+WvYytdryXz10hSWJURfpWTcPldnAiAK+f4nmAJHVKt/u/C4NmkHYlAzkAhzLViKeLqbhhIEeTTE8E+SR0Fraa0cpU5NscZqzRn/eALawCKlO7vD0E7zz3/ic46OU7fAjZmKvJ/aeR1aOITWLNLJYU1N4tmfxHC+h+/5qDO8YulDZ6oxQU/0YH9n429RE16Lu7C6I5XYTmLFc6LF8jcBL3YsXugOloYb+91XBNVH+Zf33UITFQ4l29j7SSfVhEzM6s6CGozk0SvO/SaRDzz9sL4QFSrQfDAOZTiMvUvhTqArTHZLGtjF0VB6Jd/J/999E0/jS37cLIgRqZxtT64t5/9pXuNXffeZXUSvLH43cyeH99aw6cnBZhFLLbBZt73GaThXxlWc/gFQEKCCyFko2R+dMGBFPYs3EsLqamWl286X6p7jWNYGCi8F4ENeohijUwABFRS0JMXB/G/HOLF++/sdsdfVhSMFfRTbzk971tPwoiTY+g5ycQuoOREcrx77k4sbmg3ys6DV0IZg0Je899HFmki5WV4xyZ8khfjUwwL/c+k0OXFfHP9z+NqzeWmqfzKKlTJRMPtpUSWbzk4kCebmdL/3BrwZ3s8XTy5fXfIriVBPm8ZMF094LYYYjiOko9d/Nr/DLmVi+eL11fkOqNlyOsTvInm2NXOc6uphNXRBc0yausIYhFRQUPAKyAYnWWI85OFKQPl+j21RqtgxxwijjG+FOHn9hAyX7BcGjSWpO9SJTKaRpUR+vY7y3if/8kffzsZYdfDxwGJ/y5tXSUVPlb0+9HV+PDsdPYS7QM2hFGVKK14twuyAYAKeDXNB9TskSHYFHyRVcdteopXIwVYeWlJfUuYXTieJ0IuuribcESK9NcX3VAEElxdfDb2P7aAPFPRbe/vgVRQDOBWlkyfUNzOnYS93eMb0WJa78LP5kqgyl340WjxbsNpFQVaJrQkx1CDZ7T1KnTQMqk1aW40aAp3va8Z9Ul9xPb85IiRXLZ/QWA4PnDB8J56yoSV0h5xHUa1OUq14MaRKJe3CPScgU3oMbQKurxqgtIbE6w7a2k7zP189RQ+VniSp+0ruezNEitFO9Z8Ksc63VxJrc3NW+m18q6kYVgh2ZEnYlmpk4WI4eF+ys8TDaEMCsV2hxjLHWNcC7Wg7xrLuVsWjpbG0wUAyJe9LCd0wtmDQe4zEfe7O5M070ABWqE90xRbxawVsbRD2hgCzktdR8ihyZy2ENDs3peDWWQI17MORyLqLyOkpWcjrbgyryhbSlBtLtRKgKsgDnNVKAlIJvDV9P92AlJfsEJbunsA4eOafagxaO4h1yMpl2nLlfg7kUL6cbmDY9JK38ZP5YopLeY5VUDFkLsqV3pj0L9s2LjNAdyK5mos1exreCUpukuXyCu/370EXeUu3J6TwZW0PosIn6ysGCeXDtzdTy9b03UDtyaQ8mpa6aTH2I3g+oNLeO8kL7d3ko0c4Xej4I/7uM8mcOIbO9BZ+J91LYNV5H9Qs5lLHJwjWk3G7KfvMkf1n3KOsdWZTZFAA/i3fy4Mh62v8qjeg/VdBbepeL5VAxHfmX7+lgh2xPgMbHhjAjhZN6BMg7lqsqQ3fXEd2Y5We3fIVK1WTClHz64CdJ7Sil/rEZ1KGT5MbG0eprSbeW0/dJi3s6XuV3yp4nJgWPJJr4b0/dS9VzglXP92LNxFCKgxiN5Xy97R4mrs9R1xDmf7b9mM+WPo9/g8CUEhPYka7mf/XejnjEURjPIymxdgb5hPg4D2/6GhXq67N8l1DghmmGfEEaXtaQmZXVg42OGsJr3NQ6Jpe6KfOCsCTCAvOsqY+lSaRDA6UwE0oVH4GJaDWOZxN0jE1h9g+et6C5dDnIhHQ6KoZ5t+8ATqHxz5PX8Pg3r8c3YuIK561EJWPSNTCUT2y9gO2+qCElhKgDvgVUkl9M+KqU8n8LIULAD4BG4BTwASnloj4pFY8HJeAn01lDssJBeIPAKDdY3zJAm3+cNvcYJerrieWmTQ996RBqRp5jXKRlkkPsJEMagaCGJupFG4bMcoBXSJEkSxohRPFCaKzRpuioGyUSaGAuLo5qWRnZNXWMbHQRbzG5Yd1R2rzj/Ci2mq8euwHl+SA1x8fP5CWaiz43HmTBmiavI6VAmLxpW2GuGmFxanZWe6I0a0mUsxL9PTS6jp4jNXRGBl/3k7kElrqfzgXH0DT+olISUgckFlb+MZ6b22NsMTVqtTVkm8uIbspwe9cR/CLHK+ly/rr3ThJ7SintNjFdGmZ7FfFbG4nVKSSacryr/SCbfH389cTb2DtVy8mjVZS+qhA4Op3f3kzlfRx1TSWUDSJMH1M9VXw+82Hqc70c//OHiU4Y+TqVN26guLkSZ66X/fL5ghiLjhmYnvRyPjdETbHIqm+9pbckY/F00tTmekQqk3eReIti7mejloTItdcxdKMbNs7Q5hi96DnLYSy6B2Yo8hSzJ12PV/RSoWrotQkmthRRPuKDi+RUWgqNwaNJPGMO9IEwMn6eZMtCoDidGFVBpto1tvnHCSoWJ3MmeybrKD2QRp9MoszMasuZWFPTC55vcC4rUjngv0gp9wgh/MBuIcQvgPuBp6SUfy6E+D3g94AvLlxT34wS8GPWlTNwmxPRHudPNzxIh2OMTv3saDEXFhaGNJkwA/TFQyiGdc4AEwjaWEdAFJOTBq/yFCFZwQinCFFOo+jgeflzTHLzplEKgRR5x85V+gy/Wfc0Xyr55MVPFAKrtpzBW52sufUY/73uQeo0haOGwq/t/xjak0HK/+HcWkJz0XdKHqGfNzt9FyLyPFuzc9U4yXjlQrdPqApljhilqhsL64yj+dFjNZTtVPID+zL8E5ain14qZk8vPiAtdaCwNWYbShm+wc3/t/kpvhA6QNiChyY3EvtZFXWHUjh6J4htrmamXkO9I8zdtUf4fMnL+BWNvpzkD565j8ARjY5Hx2E8ck6yXyuZzIfL9w0Q3Akhv59weA0HyjXKP/EeatrLmYlK9n/0O6wqq+Vk5kDBjEXntIUa0Ulf5hbXUoxFoen5YJu1JTiiOVyRKUhZc1vlqyhl9Hovjbef4p9bfkipMlv7562utxzG4uFjBBJ1vDDdTqUWpVFLcVNDL09e10n5834YG3/L85dCo9i+DydcsGi7UFWE30+s3klyXYqtvl78isZzqSp6h0tpfXbPnOpizjcXNaSklCPAyOzfY0KIbqAGuAe4ZfawfwOeZRE6jFoSgtIQkW1lTK8C79pJPtTwPBs9fWxxjuIVry9ZWlg8mizmhZl2Hti+FV+vSsmhLO69/ecYGk7hxjm7FqQJHY/0kyHFBMNs5mYAdBxkSf3yfGkUUubrc0mBR1Hp0sNYb5tmWL2eyleS6JEEIpbELAuSrvYwsU4nXW6hVqaoDM3w6ZrtVOtT9OWK+XpkNa9MNCKfDFF66M37wHPRV0UDJ1jalBBvRT6SSBByJ4lUl+A9eu7a3Vw1HufggqZRSf3yNYxtVfkt7zdnk/0pKCLfF13DGsGjicueHS1FP71UlHUdTHcF8YrL84daTI1TnW6uvXs/t/sPogqBDtwWPMyBd1cxeoeDXK6YzTXHaPREuM7XQ502jV/R+HTfXew42Ujzf5g4h6eQgyMXDVqxEknKnx2mNOAhU7EOA/CYkkDOT3qkjwmGCmYslrw4jGe0jIffsY47fQdZ7ci/JjyKzl+s/jF/X3Q7VksDjIUxI2/eBlvMsahVVWI0VjB0s5dEQ45bNh7i2UOr6DpajBXhgqlkFK8XJeAnsamOifU6N9+7h7uLXyOkaKgiv/UalwYpQ8eZlWCe+2peDmMRgEyWZ3vaMKTC+ppHeGrXGlr+w0COvLURBYWpUS0rZfTuJqauz/A/rvkp9dokjyQr+LOvf5i6Q0vn9HVJPlJCiEZgI7ADqJg1spBSjgghyi9wzqeBTwO48su5l85sjTahaVj1VaRqvUTWS8q6Jvj/Wx9lq3OcUtUN5FcA4laGSctiwnTzk/Amdg42UPGyoOjYDHLXwbfcK03JBDGmKSJElgxOke9Is/lUFkSjS2iUqYKba0/wxOYOpqIePBMOHNN+ElUOYg0KYmuUG6oGeG/pHqq1KZq1LHsyQQ6m63iiv4NkX4CG7gyO4ehl6XMKdz6iZQH0zSdePcOoTyC1C8+W30oj8vx9/oo1zm4tTDdrFG8cp06bRhVuLGkStzJMWBLnNOhj0XnJxr4U/XQuZMu8JMsVXCLHlbpgLrTGTFDwkbLt1KkZwIkuBG2OMe6rf40iNUVASbHJNYhLSGKWSkJq7Mi4eOV4E96DLpx7j2BOTs0tes0yzySQPb1enpIJoozSxbqCGou5U/24peRYooI17gFWk9+GVlB4u8fgYOlRHiu6CT16/vIqZ7PQY9EqCRJt82BsjPOu5qP8UeXTfNZwEqusRlMUhPMCEcRlIYyQl/AanXRXii+UP0WZItCFTszKErMkR40SpmY81CYteIuVrUIdiwDStJCTTvpjIZISXMMq+qsHzmw/z5WC0KioyICP6VWSDU0D3OsbZ3vayY5YC1UvJdB7Ry+4krXQzPlJJ4TwAT8GviClnBFibqFvUsqvAl8FCIjQJcfLKi4XSmkJRl0pqSoXmU9N8vaa/Xw4+CpFiklQ0c7cVIDjRo7vTW/jO7u3ETjgoPrZaZrHJrBmei+6EpCTOfaznVVsQBP6nCsFX6lGAF2o/FHl0/x2+VM8u6GVcM7PQDpEp3eYG9zHKVIMvIrAKRSOGyp/Fb6BXwysYnogSPu/JlFO9mDF4ud1zCsEfVeKJd+QRO8C/W+pNKqhYnLtdcTWZvhy6xNUqxJj1oj6+8ktfOvANhoOZ7AmIldc/7CQ72OqTCdZKXEKkysxpBZDo5qGPalG6rT9hAC/4qBTlzQXHQDAQPKnY7ewN1LL4NFyfH0qocMGHScmYbJv7kbUEum7InImr47UU+qMc7t755nEnIY0MaSKmIPuxdA4fn0xmz61n18p3U6XI0aR4uDtpYf5nx9vRkl5ULJV5z3P3zXJmrJevlzxLNVqkgrVgSoEhjT5h8mtPDPWTvipamoPGLifPkDuAiuOBX8fZ7GkwEQgLLDSl1aOqiA0CoFWV83M6hJ+9bYXeJvvCKaU/EHPLzN6sJz2E73kxpeuQsScnnRCCJ28EfUdKeVPZj8eE0JUza5GVQEXXyucI6erPmc3tZIKaiTLVJIVgkypxcdqD3G7/yDt+uszjf5ciiHTx8+jG9g3VcPRnmqCB3SKj2QQp4bIRWcu2nEsabGf7VRST7moAcCBk4xM4RTu05mp502jHjVwTmrsz9TgV05RqzkpUhwUKXCT5wQxS2fC7adOm6ZV10haCglp8XSymsen1vDsnk7cwxrF4xJ1YJxcOHJF+jIyhSi0vBBvwJSSYkeKTDFI55u77lw0cuHt9ytD08h5NVy+LC36BLrIlzQYNeHZ8TZ8u9w4RyfzebOuIP/OYvfTS0WPW+gxDQtxZmvzUlksjf5Bk3/adQvbm5vpCozS5JzARCFuujgUr6Y/Uczxo1U4IiolJ8E3lMVzbAIrPImVSF72fVwOY1FmDZJ9AXb566F8JxbWGWNqLizWWLQcglbPOBVqnCIl/05od4yyatUQ6ZxOxnzzyrUiJLdW9rDO0z8bVesgLg16sm56svkyVVqfi6qDBp6+GcwLhM0X+lg8G1Wx8AiJUSRRm+uxBobnlEOxUDQKVWXy+hoiawXXeE9gSI2Hk2WMHCmn5KBAxhNLmtdsLlF7AvgG0C2l/NuzfvUg8HHgz2f//Nl8NUrx+5F1FfT/eo51Nf28u2w/W1195xhPZ/NIfDW/CHfS/6NmgicMOl88ipVK57Myz+F6UkoOswsvfhrE60Udy6hmhD4a6cDIO87Om0bHyXFClPOjsS2kyx18PJBf9ldQaNLyS+YWcU7folETjhqV/NGeu3Hu8dL+19vPdJyLPY3mom+EPjT0t/iWwqDDN8Jzba3kAq5zHutz1QhML0S7hK6T86kEfUnadYEuNKJWmgPZagb2VtPydy9fsQPkUvTTS8XbO43pKiYtVVShvKmG2cVYTI2+R/fR8YKXsV9qo6e+jXibAVKgRVUqd1gE9ozQOXkEK5M589K50jf/chmLMpGg6gXJSVENnZd47hKPxetcGX626qdzOlZBZ8pKc8Tw8vdDt7PnZD2r/jYNx45iJZMXfH8sh7F4Ng7FpEr1QGOC8A2VlD4Sv2iNz0LSKJxOXJ8c4a8bf8Gtrhm+Gm3na0duoOmnWdRZB/OlZC4rUjcAHwUOCCH2zn72JfIG1A+FEJ8C+oH3X24jFJcL0VRHorWYyVUaqSoLq8TgN9Y8yyrnCG16mLKzQm4tLJKWwSPJOv5jdAuHX2om0AuVe2dQIzHMZPKScidFiTBKPz6KeEX+AoBW1tDAKg7wCkPyFCYGs5rnBWs6iqNPYeCHzfxlUyM/3dzP/TUvca/3dedNBYWfJ4v4/vg17DjcgnNEo3y/hXcwfknW91z0uXDj5OI+D0vFaWfzCzFXjcwGTiwEcrZ9b2ynmKeJ0lL000tmLIw34OLlZBt+5TBNmoucx8KsLEZMTl00WnExNVpZAxGLU7QvjK/fQ6bbCVKiprM4B6awIlP5TMrW/M10l8tYlKaJZySNe9TLcykPbfoUtXOsP7eYYzF0OMM3H7ydhzav5ZbKHr5Q8gp+5cKVFSbMDH05DwnLScxy88T0avZHqpk4WI7/lKB2KIcYmsC8SMWFZTEWAeF0UNsxxp0Vh0nJLMaME++oAXOIGi4ojaZJ35FK/lm7hZvbfsy+WB25wwH0qeklN6JgblF7L3LhWNDb5qMRwuUk1RBkfKNG5U1D3FO9jw2ufq5xptGFioWOIU2SMn/zM9JiOKfxUHg9B3Y30fxICm3fCax4nNxlLO8FRSm3877z/u50dMIO+RQzcnLeMrVZiQRWKk31g5DsqqTHbODht8XZ6nwEdfZ/25Tw6NSN7NjXSu2TAv+RCNax3ktO3DcXfZDXWIgIU5A1811VvcAG/Vw1Pil/tDB52aREWBLTUkjLHB7xFmVyLpOl6KeXihmZRPN52ROrp9k5RoMWQ3pN0hVuPCddkEq95SRgUTVaJjJjYh49DsDZBSYWKnnfshmLpok2PoM77OGp2GrSvmPAOKqAsOED68KlVhZzLLqOjVJvlNOnVPDTVW4+ENxJHQYe5fUVPUOamEgMaXHcCLAj2cJkzks44+OZI6tw9jpp/kUC/dQYuZHROd375TAWAdA1bq08xo3eoySliRJXcYZjc4ocLiSN0rTwH1fpdlcz2ATdkxUUHQclmlgehtRiIIqDDN+oUbpllK+0fZ+QYuJRVHThYMRM8UKqgf8Y3cLR8XIsS5CddFH3OLjGM3SMjmJNRLDil7ZKUxBYJuboOO5YjPZjQcZ/WMenfZ8/5xA1YdAZDcPkNDKRLIzsx4uINC2KDqns0+oxWsxzsvQWEjIWx9czzeCJEH9Xu5lPFb+Ka44BGSsNORNnx8Nr2bmpnt3b/pX3bdzNw4E1VNCC51hkWdRpu9qRuRzWwDDlDybYt3ctrzk2ILXZFddkDuVwL2YB1Ik0xybQojO0jpZhVAS47z2/ja9jin9f/y9UqBYuofLlsevZM1lH37FKvH0qoe4cjqksasqgIx5FpDNY4cmC0DPvZA1+0rue/qoQNxb14IgqKCkDeQEjuFCRRpbaH51CPurmC//2WYqjKcTIcczp6FI3DSgQQwrLQksIRsNFfGvqunN+NZ7xcyhSSfhUCNeIimaBLyLxbT+BjMXJXSQ7a6EjjSzmdBamo3Dyza65b6xldtUhLfxDOQy/zpdGb+KlkSZEvxs1MTPX4JFFQWazKNE4/pOlfLdiC/0NIdyqQXe0AvfY1WVQyWyW4HGLsVI/xzflWO0ZItXo4MWWzShGCMepwTlnnbZZOmQmgzk2DmPj+UDZ058z58CtBUcaWaSRRaRS6JMBShramcoW8ycl76bUmcCh5Hioey1izEnoiCDQl8V9aBgzHMnrW2oBC4zMZEgfLeLZKQ/7y6rwjEhEMo1lLi9DCiA3NAyAcmzxE25ejIIwpHJ9A9T99RhCVdiv+8/9pWVRIocosQaQp2++tDCvspWZqxWZy+F+aDe1j6j0fMVBuRykzOxDZgurAK6VTmMNDVP1lTDi/2oMCwFoOGSYamO0YF48i4GVTBJ86gTIFr68+T18uOJV/rjyae5/b4jDh+rp2BfEmo7OKWrIxmYuyFwOMzJJ8Ae7CKoqsT/XiKECKu1mdz4vl2kiLUlugQu4FxJmOELLl/cghABFQWZ783ns7EnMvFIQhhScnlkAC1ih2WaZYplIy7yssiqLzekZ8lWNlMhEgsCJOIefaOdPt5RysHE/W4v7GG/0QUkQJZdbmVspNkuKzOUgl7ON9LOQmcxVNZFbCgqzBLSNjc2yxkomYd8xGv/xCDwR4tsHt3Gr/zD31e8lW+5D+H1L3UQbGxubeaFgVqRsbGxWFjJnYM3EqXpilNJ9AX7vwV9Hy1j4Dp3ESiSWunk2NjY284JtSNnY2CwMUuaDKXp6UXrgtPfj1eOhYmNjczUgLlQcc0EuJsQEkADCi3bRy6eUc9vZIKUsu9hJK13jMtMHK1+j3U8vwErXuMz1wcrXaPfTWVa6xkU1pACEELuklFsW9aKXwZW0c6VrXC76YOVrtPvpwp27mNj9dGHOXUxsjQt37mJyOe20nc1tbGxsbGxsbC4T25CysbGxsbGxsblMlsKQ+uoSXPNyuJJ2rnSNy0UfrHyNdj9duHMXE7ufLsy5i4mtceHOXUwuuZ2L7iNlY2NjY2NjY7NSsLf2bGxsbGxsbGwuE9uQsrGxsbGxsbG5TBbNkBJCvEMIcVQIcVwI8XuLdd2LIYSoE0I8I4ToFkIcEkL8p9nP/1gIMSSE2Dv78845fJetcYmYL42Fqg9Wvka7n9oa3/A9BakPVr5Gu59emkaklAv+A6jACaAZcAD7gK7FuPYc2lYFbJr9ux84BnQBfwz8jq3x6tFYyPquBo12P7U1Lgd9V4NGu5/OXaOUctFWpK4Bjkspe6WUWeD7wD2LdO23REo5IqXcM/v3GNAN1FzGV9kal5B50liw+mDla7T76SWx0jUWrD5Y+RrtfnppLJYhVQMMnPXvQS6zwQuJEKIR2AjsmP3oc0KI/UKIbwohii9yuq2xQLgCjctCH6x8jXY/veo1Lgt9sPI12v30ohoXzZAS5/msoPIuCCF8wI+BL0gpZ4B/AlqADcAI8DcX+4rzfGZrXGSuUGPB64OVr9Hup7ZGloE+WPka7X46J42LZkgNAnVn/bsWGF6ka18UIYRO/j/yO1LKnwBIKceklKaU0gK+Rn6J8q2wNS4x86CxoPXBytdo91Nb4ywFrQ9Wvka7n85Z46IZUjuBNiFEkxDCAXwIeHCRrv2WCCEE8A2gW0r5t2d9XnXWYfcCBy/yVbbGJWSeNBasPlj5Gu1+egZbYwHrg5Wv0e6nZ5iLxsWJ2pN5r/h3kveKPwH8/mJddw7tupH8UuN+YO/szzuBbwMHZj9/EKiyNa58jYWq72rQaPdTW+Ny0Hc1aLT76aVptEvE2NjY2NjY2NhcJnZmcxsbGxsbGxuby8Q2pGxsbGxsbGxsLhPbkLKxsbGxsbGxuUxsQ8rGxsbGxsbG5jKxDSkbGxsbGxsbm8vENqRsbGxsbGxsbC4T25CysbGxsbGxsblM/h9pEOteGoO8bQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 前馈神经网络"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "在前面的部分中，我们了解了在PyTorch如何加载数据。接下来我们讲解如何在PyTorch中搭建、训练前馈神经网络，并完成分类任务。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. 搭建神经网络"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先我们回顾一下前馈神经网络的构造。下图展示了有两层网络层的神经网络，即（1）输入到隐藏层和（2）隐藏层到输出。输出的向量我们通常会再经过一层Softmax得到每个类别的概率，然后计算损失函数。接下来我们展示在PyTorch搭建网络的方法。注意，前馈神经网络也称多层感知机（Multi-Layer Perceptron, MLP），在后面的描述中我们会使用MLP来代表前馈神经网络。\n",
    "![](figures/2-layer-mlp.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1 用矩阵运算搭建神经网络层"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "因为神经网络里的运算其实就是在对矩阵进行操作，所以我们可以直接把网络用矩阵运算来表示。例如，给定输入`x`，一个线性层里的操作可以表示为: `x' = W x + b`，其中W和b是这个线性层的参数。遵循面向对象编程（Object Oriented Programming，OOP）的原则，我们定义一个前馈神经网络的类，把我们需要的功能封装在其中。我们可以按照如下的逻辑来设计一个两层前馈神经网络：\n",
    "```\n",
    "# 伪代码\n",
    "class MLP:\n",
    "    def __init__(self):\n",
    "        self.layer1 = xxx\n",
    "        self.layer2 = xxx\n",
    "    \n",
    "    def forward(self, x): # x是模型输入\n",
    "        # 执行self.layer1的功能\n",
    "        # 非线性激活函数\n",
    "        # 执行self.layer2的功能\n",
    "        return something\n",
    "```\n",
    "上面的代码不是一股脑地把网络直接实现，而是将网络的每一层解耦，这样可以便于我们拓展这个网络的功能（增加更多网络层或者改变网络层内部实现），并且避免这个类变得过于臃肿。接下来我们展示在PyTorch中怎么具体设计这个网络层（定义一个线性类，名为Linear）。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class Linear(nn.Module): # 继承torch.nn.Module\r\n",
    "    def __init__(self, in_features, out_features):\r\n",
    "        super(Linear, self).__init__() # super()是表示调用父类的函数，这行代码相当于nn.Module.__init__(self)\r\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features)) \r\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\r\n",
    "    \r\n",
    "    def forward(self, x): # x是模型输入\r\n",
    "        x = x.mm(self.weight) \r\n",
    "        return x + self.bias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "一些注意事项：\n",
    "1. 定义的`Linear`层需要继承`nn.Module`(`torch.nn.Module`)这个类。继承这个类之后，`Linear`这个类就能使用`nn.Module`类里定义好的函数。比如`eval()`、`to()`。 同时继承之后需要调用父类的初始化函数，即`super(Linear, self).__init__()`；\n",
    "1. 这里我们定义了两种参数，即`self.weight`和`self.bias`；\n",
    "1. 我们在定义parameter的时候，使用了`torch.randn()`，相当于对参数进行了初始化；\n",
    "1. `forward`函数表示网络里的前向过程，得到输出。由于该类继承了nn.Module，当我们实例化该类后，如`layer = Linear(...)`，`layer()`就等于`layer.forward()`；\n",
    "1. 注意这里我们没有使用Softmax层，因为后面我们使用损失函数是`torch.nn.CrossEntropyLoss`，它里面已经包含了Softmax操作。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self, in_features, hidden_features, out_features):\r\n",
    "        super(MLP, self).__init__()\r\n",
    "        self.in_features = in_features\r\n",
    "        self.layer1 = Linear(in_features, hidden_features)  # 此处的Linear()是我们前面自定义的Linear类\r\n",
    "        self.layer2 = Linear(hidden_features, out_features)\r\n",
    "        \r\n",
    "    def forward(self,x):\r\n",
    "        x = x.view(-1, self.in_features) # 将每张图片转换成向量\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = F.relu(x) # 非线性激活层，ReLU函数\r\n",
    "        return self.layer2(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**一些注意事项**：\n",
    "1. 同样的，`MLP`这个类也需要继承`nn.Module`；\n",
    "2. 层与层之间我们需要一个非线性激活层，这里我们使用ReLU;\n",
    "3. 不是所有的MLP都需要这一步`x = x.view(-1, self.in_features)`，这里只是因为我们的输入数据是二维图片，我们需要将其变为向量。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2 用PyTorch里预定义的神经网络层\n",
    "接下来我们将直接使用PyTorch里定义好的线性层（`torch.nn.Linear`）而非手动定义。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self, in_features, hidden_features, out_features):\r\n",
    "        super(MLP, self).__init__()\r\n",
    "        self.in_features = in_features\r\n",
    "        self.layer1 = nn.Linear(in_features, hidden_features) # 此处的nn.Linear是PyTorch里定义的线性层\r\n",
    "        self.layer2 = nn.Linear(hidden_features, out_features)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        x = x.view(-1, self.in_features) # 将每张图片转换成向量\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = F.relu(x) # 非线性激活层，ReLU函数\r\n",
    "        return self.layer2(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "这个MLP同前面我们的手动定义的MLP的不同之处就在于，`self.layer1`和`self.layer2`是直接调用的PyTorch中定义好的`nn.Linear`。`torch.nn`中还定义了许多网络层，如卷积层、池化层等等。详情可见[该链接](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#_1)。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.3 神经网络的前向过程 Foward propogation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 这里我们继续以第一张图片为例来演示神经网络的前向过程\r\n",
    "# 我们首先实例化一个MLP，\r\n",
    "img, label = data_train[0]\r\n",
    "img = img.view(-1)  # view(-1)表示把矩阵变成一维向量: (1,28,28) --> (784,)\r\n",
    "feat_dim = len(img) # 计算输入的特征的维度（图片的维度）\r\n",
    "num_classes = 10\r\n",
    "model = MLP(in_features=feat_dim, hidden_features=256, out_features=num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (layer2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 我们定义一个device变量，用于决定我们是否要把数据和模型放在GPU上运行\r\n",
    "# 如果没有安装cuda的话，则使用cpu\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 将模型和数据放在device上（放在cpu或者gpu上）\r\n",
    "model = model.to(device) \r\n",
    "img = img.to(device)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "output = model(img)\r\n",
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0387, -0.0440, -0.1172,  0.0814, -0.0507, -0.1659,  0.0801,  0.0254,\n",
       "         -0.0079, -0.0690]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型的输出是一个长度为10的向量，我们可以认为每个元素代表对应类别的概率（这里是未归一化的概率，通常称为logits）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 我们取出其中最大值对应的类别，并和真实类别就行比较\r\n",
    "predicted = output.argmax()\r\n",
    "print('预测标签:', predicted.item(), '; 实际标签:', label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "预测标签: 3 ; 实际标签: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 训练神经网络\n",
    "前面我们讲述了怎么搭建一个神经网络以及如何得到对应数据的输出，但是模型里的参数并没有优化过，所以预测效果往往很差。接下来我们讲解如何训练一个神经网络。\n",
    "```\n",
    "# 伪代码\n",
    "def train():\n",
    "    for epoch in num_epochs:\n",
    "        # 取一个batch的数据\n",
    "        # 前向传播forward\n",
    "        # 计算损失函数\n",
    "        # 反向传播backward\n",
    "        # 更新参数\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 我们定义一个train函数来封装我们的训练过程\r\n",
    "def train(model, data, num_epochs=5, learning_rate=1e-3, batch_size=32):\r\n",
    "    # 定义一个优化器，Adam优化器是梯度下降法的一个变种\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\r\n",
    "                                 lr=learning_rate, \r\n",
    "                                 weight_decay=1e-5) # weight_decay表示L2正则项\r\n",
    "    \r\n",
    "    # 把训练数据封装到DataLoader，这样便于我们以及选取batch以及打乱数据顺序\r\n",
    "    train_loader = torch.utils.data.DataLoader(data, \r\n",
    "                                               batch_size=batch_size, \r\n",
    "                                               shuffle=True)\r\n",
    "    # 定义损失函数\r\n",
    "    criterion = nn.CrossEntropyLoss()\r\n",
    "    \r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        loss_total = 0 # 定义一个loss_total变量来记录我们的loss变化\r\n",
    "        for data in train_loader:\r\n",
    "            # 梯度清零\r\n",
    "            optimizer.zero_grad()\r\n",
    "            \r\n",
    "            img, label = data\r\n",
    "            img = img.to(device)\r\n",
    "            label = label.to(device)\r\n",
    "            \r\n",
    "            # 前向传播和反向传播 \r\n",
    "            output = model(img)\r\n",
    "            loss = criterion(output, label)\r\n",
    "            loss.backward()\r\n",
    "            \r\n",
    "            # 优化参数\r\n",
    "            optimizer.step()\r\n",
    "            \r\n",
    "        loss_total += loss.item() \r\n",
    "        print('Epoch: {}, Training Loss: {:.4f}'.format(epoch+1, loss_total))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "train(model, data_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Training Loss: 0.0634\n",
      "Epoch: 2, Training Loss: 0.0846\n",
      "Epoch: 3, Training Loss: 0.0767\n",
      "Epoch: 4, Training Loss: 0.0186\n",
      "Epoch: 5, Training Loss: 0.0851\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "@torch.no_grad() # 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\r\n",
    "def test(model, data, batch_size=128):\r\n",
    "    num_correct = 0 # 预测正确的图片数\r\n",
    "    num_total = 0 # 总共的图片数\r\n",
    "    \r\n",
    "    test_loader = torch.utils.data.DataLoader(data, \r\n",
    "                                              batch_size=batch_size, \r\n",
    "                                              shuffle=False)\r\n",
    "    for data in test_loader: # 按batch取出测试集中的数据\r\n",
    "        img, label = data\r\n",
    "        img = img.to(device)\r\n",
    "        label = label.to(device)\r\n",
    "        output = model(img)\r\n",
    "        predicted = output.argmax(1)\r\n",
    "        num_total += len(label)\r\n",
    "        num_correct += (predicted == label).sum()\r\n",
    "\r\n",
    "    print('共有{}张图片，准确率为: {:.2f}%'.format(num_correct, 100 * num_correct / num_total))    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "test(model, data_train)\r\n",
    "test(model, data_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "共有59292张图片，准确率为: 98.82%\n",
      "共有9746张图片，准确率为: 97.46%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 卷积神经网络 (CNN)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先我们回归一下卷积神经网络CNN的结构图，![](figures/cnn.png)\n",
    "\n",
    "它可以被拆分为两个块（block）：特征提取部分（feature extractor）和分类部分（classification）。特征提取部分由多个卷积层构成，而分类部分由全连接层，即前馈神经网络。因此我们在定义CNN的时候也可以按照这么两部分来定义。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "class CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(CNN, self).__init__()\r\n",
    "        self.features = nn.Sequential( \r\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(32, 64, 7)\r\n",
    "        )\r\n",
    "        self.classifier = nn.Sequential(\r\n",
    "            nn.Linear(64, 120),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(120, 10)\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.features(x)\r\n",
    "        x = x.view(-1, 64) # 铺平成向量，flattening \r\n",
    "        x = self.classifier(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**注意**：\n",
    "1. 这里我们不再手动定义卷积层了，直接调用`nn.Conv2d`。对于`nn.Conv2d(1, 16, 3, stride=2, padding=1)`，其中`1`表示输入有1个通道（channel），`16`表示该层的输出有`16`个通道，`stride=2`表示卷积的平移步长是2，`padding=1`表示填充的幅度。\n",
    "\n",
    "2. 我们在定`self.features`的时候用到了`nn.Sequential()`，它是一个将多个网络层（和激活函数）结合起来的容器。用户可以通过`nn.Sequential()`来组合自己想搭建的神经网络。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model = CNN().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "train(model, data_train) # 调用之前定义好的train函数"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Training Loss: 0.0270\n",
      "Epoch: 2, Training Loss: 0.0568\n",
      "Epoch: 3, Training Loss: 0.0226\n",
      "Epoch: 4, Training Loss: 0.0695\n",
      "Epoch: 5, Training Loss: 0.0077\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "test(model, data_train)\r\n",
    "test(model, data_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "共有59399张图片，准确率为: 99.00%\n",
      "共有9823张图片，准确率为: 98.23%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 自编码器 AutoEncoder\n",
    "![](figures/autoencoder.png)\n",
    "自编码器可以看作是一个试图从输出中重建输入的神经网络。它包含两个部分：编码器和解码器。编码器负责对输入进行编码，而解码器负责对编码后的信息进行重建。因此，作为一个示例，我们构建如下的由卷积神经网络构成的自编码器。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "class Autoencoder(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Autoencoder, self).__init__()\r\n",
    "        # 我们用前面CNN中使用的特征提取部分当作这里的编码器encoder\r\n",
    "        self.encoder = nn.Sequential( \r\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(32, 32, 7)\r\n",
    "        )\r\n",
    "        \r\n",
    "        # 对于解码器decoder，我们需要使用nn.ConvTranspose2d\r\n",
    "        self.decoder = nn.Sequential(\r\n",
    "            nn.ConvTranspose2d(32, 32, 7),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\r\n",
    "            nn.Sigmoid()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.encoder(x)\r\n",
    "        x = self.decoder(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "其中编码器由卷积层构成，解码器都由反卷积层构成。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "autoencoder = Autoencoder().to(device) # device is either 'cpu' or 'cuda'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# 大体上跟前面train()函数一致，只是损失函数和输入有所不同\r\n",
    "def train_autoencoder(model, data, num_epochs=10, learning_rate=1e-3, batch_size=32):\r\n",
    "    # 定义一个优化器，Adam优化器是梯度下降法的一个变种\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\r\n",
    "                                 lr=learning_rate, \r\n",
    "                                 weight_decay=1e-5) # weight_decay表示L2正则项\r\n",
    "    \r\n",
    "    # 把训练数据封装到DataLoader，这样便于我们以及选取batch以及打乱数据顺序\r\n",
    "    train_loader = torch.utils.data.DataLoader(data, \r\n",
    "                                               batch_size=batch_size, \r\n",
    "                                               shuffle=True)\r\n",
    "    # 定义损失函数，这里我们使用MSE loss来衡量输出和输入的差别\r\n",
    "    criterion = nn.MSELoss()\r\n",
    "    \r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        loss_total = 0 # 定义一个loss_total变量来记录我们的loss变化\r\n",
    "        for data in train_loader:\r\n",
    "            # 梯度清零\r\n",
    "            optimizer.zero_grad()\r\n",
    "            \r\n",
    "            img, _ = data\r\n",
    "            img = img.to(device)\r\n",
    "            \r\n",
    "            # 前向传播和反向传播 \r\n",
    "            output = model(img)\r\n",
    "            loss = criterion(output, img)\r\n",
    "            loss.backward()\r\n",
    "            \r\n",
    "            # 优化参数\r\n",
    "            optimizer.step()\r\n",
    "            \r\n",
    "        loss_total += loss.item() \r\n",
    "        print('Epoch: {}, Training Loss: {:.4f}'.format(epoch+1, loss_total))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "train_autoencoder(autoencoder, data_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Training Loss: 0.0096\n",
      "Epoch: 2, Training Loss: 0.0059\n",
      "Epoch: 3, Training Loss: 0.0063\n",
      "Epoch: 4, Training Loss: 0.0053\n",
      "Epoch: 5, Training Loss: 0.0056\n",
      "Epoch: 6, Training Loss: 0.0053\n",
      "Epoch: 7, Training Loss: 0.0049\n",
      "Epoch: 8, Training Loss: 0.0057\n",
      "Epoch: 9, Training Loss: 0.0042\n",
      "Epoch: 10, Training Loss: 0.0051\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# 观察生成的图片的质量\r\n",
    "test_loader = torch.utils.data.DataLoader(data_test, \r\n",
    "                                          batch_size=8, \r\n",
    "                                          shuffle=False)\r\n",
    "\r\n",
    "\r\n",
    "for i, data in enumerate(test_loader):\r\n",
    "    img, _ = data\r\n",
    "    img_new = autoencoder(img).detach().numpy()\r\n",
    "    img = img.numpy()\r\n",
    "    plt.figure(figsize=(8, 2))\r\n",
    "    for j in range(8):\r\n",
    "        plt.subplot(2, 8, j+1)\r\n",
    "        plt.imshow(img_new[j].squeeze())\r\n",
    "        plt.subplot(2, 8, 8+j+1)\r\n",
    "        plt.imshow(img[j].squeeze())\r\n",
    "    if i >= 2:\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-57c99040e8ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimg_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-7a1c49b82eb1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gnn\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "参考资料：\n",
    "\n",
    "[1] https://pytorch-cn.readthedocs.io/zh/latest/#pytorch\n",
    "\n",
    "[2] https://www.cs.toronto.edu/~lczhang/360/lec/w05/autoencoder.htmlv"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('gnn': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "c15e7b3ada59775ba965e50ee079f50e3ab56271f763ae3479ab85d54a12c16f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}